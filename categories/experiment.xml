<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="https://alix-tz.github.io/phd/assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>A research (b)log (Posts about experiment)</title><link>https://alix-tz.github.io/phd/</link><description></description><atom:link href="https://alix-tz.github.io/phd/categories/experiment.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2022 &lt;a href="https://alix-tz.github.io/phd/"&gt;Alix Chagué&lt;/a&gt; CC-BY</copyright><lastBuildDate>Wed, 19 Oct 2022 18:50:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>007 - WikiCREMMA</title><link>https://alix-tz.github.io/phd/posts/007/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;"WikiCREMMA" (or CREMMA-Wiki, or CREMMA-Wikipedia) is (are?) the name(s) Thibault Clérice and I gave to a dataset created within the perimeter of the CREMMA funding. In 2022, we were able to use this funding to hire several students from the &lt;a href="https://www.chartes.psl.eu/"&gt;École nationale des chartes&lt;/a&gt; to produce entirely new transcriptions of documents from various periods (from Medieval times to 21st century), or to align already existing transcriptions with the corresponding images. We will hopefully have occasions to present this experiment further in the months to come, but today I would like to talk about the specific case of WikiCREMMA.  &lt;/p&gt;
&lt;p&gt;Unlike the other CREMMA datasets[^They can all be found via the &lt;a href="https://htr-united.github.io/catalog.html"&gt;HTR-United catalog!&lt;/a&gt;], WikiCREMMA also consisted in creating new images. Using exerpts from &lt;a href="https://github.com/PonteIneptique/wikicremma"&gt;randomly selected&lt;/a&gt; Wikipedia articles (in French), we created forms which were then printed before we asked volunteers to copy the text by hand using the tools of their choice, thus collecting examples of nowadays handwritings.  &lt;/p&gt;
&lt;p&gt;The form mostly consists in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;explanations regarding the context of the experiment,&lt;/li&gt;
&lt;li&gt;instructions on how to fill the form,&lt;/li&gt;
&lt;li&gt;a short section where contributors can add their names, their writing hand (left or right) and their gender,&lt;/li&gt;
&lt;li&gt;the excerpt to copy,&lt;/li&gt;
&lt;li&gt;and a blank space where contributors ought to write.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each form offer a different excerpt to copy: it is thus possible for volunteers to contribute many forms. The excerpts were collected by sending requests to the "&lt;a href="https://fr.wikipedia.org/wiki/Sp%C3%A9cial:Page_au_hasard"&gt;Page au hasard&lt;/a&gt;" feature available in Wikipedia (in English, see "&lt;a href="https://en.wikipedia.org/wiki/Special:Random"&gt;random article&lt;/a&gt;").  &lt;/p&gt;
&lt;p&gt;Once the forms were filled, we automatically &lt;a href="https://github.com/alix-tz/cremmawiki-anonymizer"&gt;anonymized them&lt;/a&gt; and then uploaded them on eScriptorium. This anonymization mostly meant adding a big black rectangle over the part of the page where contributors are invited to give us details about who they are. Once in eScriptorium, the images are segmented (aka lines of text are detected on the image) and then transcribed. We ignore all the printed text and only focus on the handwritten elements.  &lt;/p&gt;
&lt;p&gt;Since we asked volunteers to copy a text, it is impossible to avoid crossed out words, blanks or mispellings. Therefore, even if we possess the original text, we did not automatize the transcription. This manual transcription takes time but it allows us to respect what was actually written by a volunteer. On the other hand, having access to the text they were asked to copy allows us to read them very quickly and to lift any doubt regarding what we should be reading!&lt;/p&gt;
&lt;p&gt;We created several batches of forms in order to test out the success (or failure) of our project. They don't always have the same size: Batch-01 contains 10 images whereas Batch-04 has 96 of them. Initially, we imagined leaving stacks of these forms in different spots, giving volunters the possibility to send us their form after they filled it. However, even if we dream big, it seemed safer to start with asking people around us. I've asked friends, colleagues, classmates, but also very random people to participate in this experiment -- maybe you, reader, also contributed! Overall, as far as I am concerned, this has been a lot of fun! &lt;/p&gt;
&lt;p&gt;As of Fall 2022, more than 135 people took part in the experiment and we collected more than 250 pages. Not everything was transcribed yet, but we were already able to publish 215 files in the &lt;a href="https://github.com/HTR-United/cremma-wikipedia"&gt;CREMMA-WIKIPEDIA&lt;/a&gt; repository. It adds up to a total of 1~181 lines and 57~490 characters for contemporary handwritings in French. &lt;/p&gt;
&lt;p&gt;On top of the images and the transcription, I proposed to add a series of metadata. They would allow potential users of the dataset to sort the files according to several criterias. They include the writing hand, the color of the ink or else the type of tool used to write (pencil / marker / ink pen / etc).&lt;/p&gt;
&lt;p&gt;We were already able to use part of this dataset since it was included in the train set of &lt;a href="https://zenodo.org/record/6657809#.Y1BEtEyZOuU"&gt;Manu McFrench&lt;/a&gt;, an HTR model for modern and contemporary French!&lt;/p&gt;
&lt;p&gt;I have lots of ideas of future usages and developments for this dataset so it will be back in other posts of this blog!&lt;/p&gt;</description><category>experiment</category><category>wikicremma</category><guid>https://alix-tz.github.io/phd/posts/007/</guid><pubDate>Wed, 19 Oct 2022 18:49:00 GMT</pubDate></item></channel></rss>