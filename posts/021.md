<!--
.. title: 021 - McCATMuS #4 - Cleaning data, collection metadata
.. slug: 021
.. date: 2024-08-29
.. tags: CATMuS, HTR, datasets
.. category: dataset
.. link: 
.. status: draft
.. description: 
.. type: text
-->

Data preparation for CATMuS would certainly have taken a lot of time and nerve racking had I not been able to benefit from Thibault's experience with CATMuS Medieval. Not only was I able to build from the workflow he put in place when building it, I also heavily relied on his scripts to parse and build the final dataset. Most of these steps are presented in [Thibault Clérice, Ariane Pinche, Malamatenia Vlachou-Efstathiou, Alix Chagué, Jean-Baptiste Camps, et al.. CATMuS Medieval: A multilingual large-scale cross-century dataset in Latin script for handwritten text recognition and beyond. 2024 International Conference on Document Analysis and Recognition (ICDAR), 2024, Athens, Greece](https://univ-paris8.hal.science/hal-04453952v1).

I started with downloading the all the datasets, keeping track of the official releases, then I manually reorganized all the datasets so that the data would always be under `{dataset_repo}/data`, which made later manipulations easier. With [Chocomufin](https://github.com/PonteIneptique/choco-mufin), I generated a character table for each dataset and spent time building a conversion table for each group of dataset with similar transcription guidelines. For example, it meant replacing all the `¬` with `-` in the SETAF datasets. For the earlier CREMMA datasets, I also needed to change the character used for corrections in the document: CREMMA used a structure where `>hello<` is a pseudo mark-up signaling a crossed out words. Following the guidelines elaborated by Ariane Pinche and the CATMuS Medieval guidelines, this should be transcribed as `⟦hello⟧`. [`chocomufin convert`](https://github.com/PonteIneptique/choco-mufin?tab=readme-ov-file#commands) allow to use a pivot table to make this kind of replacement very easily. The result of the conversion is saved under a `.catmus.xml` file, in order not to lose the original version of the dataset.

For each of the dataset repositories, I listed the directories under data and created a new table. This table was used as a basis to start collecting additional metadata, like the language used at document level, rather than at dataset level, or the type of writing (print, handwritten or typewritten). For some multilingual datasets, if the distinction between the different language was easy to make, I sometimes artificially created a distinction among the documents. It was for example the case with Gallicorpora's "HTR-imprime-18e-siecle", in which some documents contain English pages.

I spent two long afternoons assigning each document its correct call number (or shelfmark), allowing for a precise evaluation of the diversity of documents in McCATMuS. In the few cases were the original manuscript used to build the ground truth had no corresponding call number, I simply made one up. Thus, "cph_paris_tissage_1858/" in "timeuscorpus" is now associated to its corresponding call number at the Paris' archive center (Paris, AD75, D1U10 386), but CREMMAWiki's "batch-04", which is composed of documents we created for the project, as a made up call number: "nobs_cremma-wikipedia_b04".

The metadata associated with McCATMuS are different from the ones available in CATMuS Medieval. As can be seen on HuggingFace's [dataset viewer](https://huggingface.co/datasets/CATMuS/modern), McCATMuS offers metadata on language, date (not_before, not_after), region type and line type using SegmOnto's classification, writing type (handwritten, typewritten or printed[^writing_type]), call number, document genre (document of practice, poetry, epistolary, etc.), project having created the original data and on color (a simple true/false value).

CATMuS Medieval's metadata differ in three ways:

- the data is currently displayed as a 2-digit century which is less precise
- since there are only handwritten documents in the dataset, "writing_type" would be useless. Rather, one of CATMuS Medvieval's strengths is the "script type" metadata entry, which follows a classification (caroline, textualis, hybrida, etc) that has no equivalent for more recent handwriting.
- genre is complemented by a verse metadata entry, allowing a general differentiation between prose and verse.

Since the modelling of the metadata was different between the two datasets, although my goal was to follow as much as possible the medieval example, I played with the script Thibault elaborated to build the dataset in the form of PARQUET files, ready to be uploaded on HuggingFace. This included updating the mapping to segmOnto's vocabulary to normalize the values in line_type and region_type, filtering some types of ligne such as the ones identified as signatures (I don't think they make sense in the context of a generic dataset), etc. 


[writing_type]: McCATMuS could thus be used to train a classifier.
