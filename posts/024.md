<!--
.. title: 024 - It did a good job
.. slug: 024
.. date: 2023-02-28 05:41:40 UTC-05:00
.. tags: static website
.. status: draft
.. category: resources
.. link: 
.. description: 
.. type: text
-->


Because it was repeated so many times, it made me wonder "what does it even mean to do a very good job in this context?". This is what I want to explore in this blog post.

First of all, I think there is a postulate in this sentence which reflects how we tend to consider IA in particular and software in general as a series of agents, capable of acting on their own accord. It's almost like we consider that the software is not simply executing a task according to how it is programmed, but "doing a job" as we humans do, with our own share of free will. We tend to fall into the easy trap of anthropomorphism when it comes to AI-based software. In many cases, it is like we surrender our own agency in the digital world. 






<!--Nevertheless, it made me think. About the anthropomorphism of artificial intelligence (IA) and software. About the presumption that IA is a subaltern. And about the vagueness of such an appreciation.  -->

I think we should collectively be aware of our tendency to consider IA and software in general as agents partially acting out of our own control. It places us in a position where we accept that, as users,  we have no influence over the software's behavior, whether it utilizes AI or not. Which is fairly wrong, if you want my opinion. To me, there is a distinction between perceiving software as performing a set of predefined tasks versus it "doing a job" as we humans do, with a descent share of free will. I think refusing to give into anthropomorphism is a way to refuse to surrender our own agency in the digital world.

Marcello Vitali-Rosati is a hundred times better than me for thinking about our interactions [with IA](http://blog.sens-public.org/marcellovitalirosati/intelligence-artificielle-modeles.html) and with [our digital environment](https://journals.openedition.org/revuehn/371). He might not agree with my previous point, although I am merely calling for a clearer distinction between human and machines, when this difference is obvious.  

Recently, I saw more investigations and articles ([here](https://africanarguments.org/2023/03/the-invisible-labour-of-africa-in-the-digital-revolution/) or [here](https://time.com/6247678/openai-chatgpt-kenya-workers/) or again [here](https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots)) finally tackling the problem of the fundamental role played by underpaid annotators in the advancement of IA. 



