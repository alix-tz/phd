<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="https://alix-tz.github.io/phd/assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>A research (b)log (Posts by Alix Chagué)</title><link>https://alix-tz.github.io/phd/</link><description></description><atom:link href="https://alix-tz.github.io/phd/authors/alix-chague.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="https://alix-tz.github.io/phd/"&gt;Alix Chagué&lt;/a&gt; CC-BY</copyright><lastBuildDate>Fri, 28 Nov 2025 23:18:17 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>025 - Critically reading "The Writing Is on the Wall for Handwriting Recognition"</title><link>https://alix-tz.github.io/phd/posts/025/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;blockquote&gt;
&lt;p&gt;A little disclaimer for once, because I usually prefer to praise if I name people. I do not know Dan Cohen nor his work, my criticism of his article is not directed against him personally, but rather it takes his text as one example among many of the kind, that develop the same type of discourse and contain the same type of flaws.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Plus tôt cette semaine, mon collègue Louis-Olivier Brassard m'a demandé mon avis sur le &lt;a href="https://newsletter.dancohen.org/archive/the-writing-is-on-the-wall-for-handwriting-recognition/"&gt;dernier billet&lt;/a&gt; posté par Dan Cohen, qu'il a intitulé "&lt;em&gt;The Writing Is on the Wall for Handwriting Recognition&lt;/em&gt;", ajoutant un sous-titre annonçant la couleur: "&lt;em&gt;One of the hardest problems in digital humanities has finally been solved&lt;/em&gt;". J'avais envie de rendre un peu plus public ma lecture critique, donc j'en tire un billet de blog, en français pour une fois.&lt;/p&gt;
&lt;p&gt;J'ai lu avec attention cet article car le sujet m'intéresse (forcément), mais je ne cache pas que je débute en général ce genre de lecture avec un a priori négatif. C'est le traitement que je réserve à tous ces postes, de blog ou sur les réseaux sociaux, qui annoncent à tour de bras que l'IA générative a révolutionné ceci ou cela -- ceci et cela étant généralement des problèmes qui ont occupé des chercheur-ses et ingénieur-es depuis des années, et qui donnent lieu à des débats parfois houleux voire insolvables. Tous ces billets contribuent à alimenter l'esbrouffe de l'IA générative et à saper notre capacité collective déjà pas mal usée à développer une pensée critique à son endroit. &lt;!--J'essaie quand même d'être honnête et de faire attention à mes propres biais dans ce que j'en tire ci-dessous.--&gt;&lt;/p&gt;
&lt;p&gt;Le billet de Dan Cohen fait suite à la sortie de la version 3 de Gemini, le modèle d'IA générative de Google, publicisé comme le modèle de Google "le plus intelligent à date" ("&lt;em&gt;our most intelligent model yet&lt;/em&gt;" dit Google). Comme à chaque fois qu'un nouveau modèle de ce type sort, plusieurs utilisateurs partagent les résultats de leurs "expérimentations" avec ces modèles. Dan Cohen n'est pas le seul, par exemple Mark Humphries a aussi posté le même jour &lt;a href="https://generativehistory.substack.com/p/gemini-3-solves-handwriting-recognition"&gt;un billet sur le sujet&lt;/a&gt; intitulé sobrement "&lt;em&gt;Gemini 3 Solves Handwriting Recognition and it’s a Bitter Lesson&lt;/em&gt;". J'ai beaucoup vu ces deux billets relayés sur BlueSky, salués par des chercheurs que j'estime occuper des place d'autorité dans le domaine de la transcription automatique. Après avoir lu le billet de Dan Cohen, je me suis retrouvée assez agacée de ces relais: je ne suis pas convaincue que le texte ait été bien lu par ceux qui l'ont relayé sur BlueSky.&lt;/p&gt;
&lt;p&gt;A mon avis, le problème du billet que Dan Cohen est double: 1) il développe un discours universel sur un outil qu'il n'a testé que sur sélection minime d'exemples qui ne disent presque rien des problèmes que rencontrent les utilisateurs de la transcription automatique sur les documents anciens, 2) sa démonstration tient sur des arguments fallacieux.  &lt;/p&gt;
&lt;h3&gt;Un problème de rigueur scientifique&lt;/h3&gt;
&lt;p&gt;Sur le premier point tout d'abord. Dan Cohen utilise trois exemples qui ne sont pas du tout représentatifs des défis de la transcription automatique. D'emblée, cela justifierait une note de bas de page à son sous-titre: il dit "l'un des problèmes les plus difficiles des humanités numériques a enfin été résolu", j'ajoute "en ce qui concerne les documents épistollaires rédigés en anglais durant la première moitié du XIXe siècle par des personnalités dont des biographies ont été écrites, voire dont la correspondance à déjà été éditée"&lt;sup id="fnref:precision_inedit"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/025/#fn:precision_inedit"&gt;1&lt;/a&gt;&lt;/sup&gt; car c'est ce qu'il a testé. Ca réduit déjà pas mal la portée de ses résultats, non? D'ailleurs, étant donné que le modèle ne parvient pas à transcrire le troisème exemple, on pourrait même ajouter que cela ne concerne en plus que les documents dont la mise en page est simple.&lt;sup id="fnref:standard_layout"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/025/#fn:standard_layout"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Ce premier point est vraiment problématique parce qu'il s'agit d'un texte publié par une personne qui a une autorité scientifique et qui devrait donc faire preuve de rigueur scientifique, même si ce texte n'est qu'une newsletter et pas un article ou un ouvrage édité. J'attendrais de cette rigueur scientifique qu'on se limite à tirer des conclusions sur ce que l'on a réussi à démontrer au lieu de jouer les Cassandre avec des (sous-)titres tape-à-l'oeil. On peut avoir la conviction que Gemini est capable de traiter avec succès bien d'autres cas que ceux présentés par Dan Cohen, mais cela relève de la croyance, pas de la démonstration scientifique. Je pense que c'est un sujet qui doit être discuté plus largement, dans un contexte où l'IA nous est messianiquement servie à toutes les sauces, mais Marcello Vitali-Rosati en parle bien dans &lt;a href="https://blog.sens-public.org/marcellovitalirosati/2025-11-htr.html"&gt;son dernier billet&lt;/a&gt; ou encore, sous un autre angle et qui sort des usages par le monde académique, il y a le récent travail d'&lt;a href="https://www.polytechnique-insights.com/tribunes/digital/comment-se-proteger-du-syndrome-de-stockholm-technologique-face-a-lia/"&gt;Hamilton Mann&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Il se trouve que le jour où Louis-Olivier m'a demandé de lire le texte de Dan Cohen, j'avais aussi lu celui de &lt;a href="https://digitalorientalist.com/2025/11/25/teaching-bengali-digital-texts-to-anglophone-undergraduates-what-voyant-reveals-about-the-infrastructural-bias-of-dh-tools/"&gt;Sunayani Bhattacharya&lt;/a&gt; qui a formé ses élèves du Saint Mary’s College en Californie à l'analyse de texte avec &lt;a href="https://voyant-tools.org/"&gt;Voyant Tools&lt;/a&gt; et qui traite aussi de transcription automatique au détour de son billet. Elle explique que, dans l'optique de proposer une ouverture vers le Sud Global à ses étudiant-es, elle les a fait travailler sur des textes en Bengali (même si aucun ne sait parler ou lire le Bengali). Je trouve l'exercice intéressant et prometteur tel qu'elle le présente. Après avoir développé chez ses élèves une familiarité avec ce à quoi ressemble les textes de presse correctement édités dans Voyant Tools, elle leur a montré ce qu'on obtient quand on tente de faire tourner Voyant Tools sur des textes directement sortis d'un logiciel d'OCR. Ces textes contiennent énormément de bruit et parfois n'utilisent même pas les bons jeux de caractères. Cela lui permet de donner un exemple très concret à ses étudiant-es des limites des infrastructures logicielles dès qu'il s'agit de traiter de textes en langues indiennes. Elle conclut en redisant l'utlité de donner aux étudiant-es une meilleure idée de ce à quoi ressemblent les biais anglophones dans la technologie quand on est sur le terrain. Dans un texte comme celui dont je discute dans ce billet, ce biais anglophone (et j'ajouterai même moderniste) saute aux yeux.&lt;/p&gt;
&lt;h3&gt;Une démonstration bancale&lt;/h3&gt;
&lt;p&gt;Maintenant, concernant le deuxième point, il suppose de regarder d'un peu plus près ce que Dan Cohen nous dit et les exemples qu'il donne. Il y a des imprécisions qui doivent être relevées, mais aussi des extraits qui ne correspondent pas aux affirmations qui sont faites dans le billet.  &lt;/p&gt;
&lt;p&gt;Une imprécision qui commence justement par la question de la précision des modèles. J'en ai déjà parlé dans &lt;a href="https://alix-tz.github.io/phd/posts/012/"&gt;un précédent billet&lt;/a&gt; car il me semble que c'est l'un des sujets où les chercheurs font le plus preuve de paresse: de quelle précision on parle, et quelles sont les limites de ces mesures de précision ? Dan Cohen affirme que "&lt;em&gt;les meilleurs logiciel d'HTR ont du mal à atteindre 80% de précision&lt;/em&gt;". Comme il clarifie que cela signifie 2 mots faux tous les 10 mots, déjà on s'aperçoit qu'il nous parle de taux d'erreur au mot et non au caractère. Un tel taux d'erreur ne dit rien de la lisibilité du texte puisqu'une seule erreur suffit pour que le mot soit compté comme faux. Dans une phrase comme "&lt;em&gt;the hardest problem in digtial humaities has finolly beeen sol ved&lt;/em&gt;", un mot sur deux contient une faute, pourtant il me semble que la phrase est parfaitement lisible.&lt;sup id="fnref:lisible"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/025/#fn:lisible"&gt;4&lt;/a&gt;&lt;/sup&gt; Pour mettre les choses en perspective, le taux de précision au caractère dans cette phrase, lui, est de 90.77% (d'après un logiciel comme &lt;a href="https://huggingface.co/spaces/lterriel/kami-app"&gt;KaMI&lt;/a&gt;). En plus de cette imprécision de départ, l'affirmation de Dan Cohen sur les difficultés des logiciels traditionnels me semble fause. Je ne vois pas sur quelle source il se base. Pour des documents comme ceux qu'il teste, on est bien au-delà des 80% de précision, y compris au mot, et ce avec plusieurs modèles et plusieurs logiciels.&lt;/p&gt;
&lt;p&gt;Comme cette affirmation m'a surprise, j'ai voulu regarder si vraiment le modèle de Transkribus avait fait autant de fautes que ça. Bien sûr, il a fait des erreurs. Quand on regarde le document source, on voit que certaînes sont compréhensibles dans un contexte zero-shot: lorsque Boole trace deux "l" à la suite, son deuxième "l" ressemble à un "e" avec une boucle très très petite. C'est ce qui explique que la prédiction de Transkribus contient des erreurs sur "&lt;em&gt;tell&lt;/em&gt;" (lu "&lt;em&gt;tele&lt;/em&gt;") sur la page de gauche, et "&lt;em&gt;All&lt;/em&gt;" (lu "&lt;em&gt;Ale&lt;/em&gt;") sur la page de droite. Pour savoir quelle était vraiment l'ampleur des erreurs de Transkribus, j'ai proposé ma propre transcription de la double page, ligne par ligne (en suivant l'ordre des lignes tiré de la segmentation dans Transkribus, et en m'aidant un peu de la lecture proposé par Gemini). Quand je calcule le taux de précision sur cet extrait, j'obtiens une précision au caractère d'environ 95,1% et une précision au mot de 88%.&lt;sup id="fnref:precision_error_tkb"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/025/#fn:precision_error_tkb"&gt;3&lt;/a&gt;&lt;/sup&gt; Largement perfectible donc, mais on n'est pas dans une situation catastrophique comme le laisse supposer le préambule.&lt;/p&gt;
&lt;p&gt;Maintenant, si on regarde la transcription de Gemini, on s'aperçoit qu'il y a en fait aussi des erreurs, alors que Dan Cohen nous dit "&lt;em&gt;Gemini transcribed the letter perfectly&lt;/em&gt;". Par exemple, Gemini transcrit, sur la page de droite, "&lt;em&gt;occasionally by&lt;/em&gt;" (Transkribus l'avait transcrit "&lt;em&gt;occasion by&lt;/em&gt;"), en générant comme précision complémentaire dans une section de notes que "&lt;em&gt;On the right page (line 8), the handwriting becomes very scribbled. It appears to say 'take a long walk occasionally try &amp;amp; once or twice...' or possibly 'occasionally by &amp;amp; once or twice...'.&lt;/em&gt;" Donc Gemini, échoue ici à proposer de lire une césure qui fait pourtant sens et préfère ajouter un mot dans sa transcription. Le problème ce n'est pas que Gemini n'ai pas fait une transcription parfaite bien sûr, mais plutôt que Dan Cohen l'affirme sans relever cette erreur.&lt;/p&gt;
&lt;p&gt;On a le même problème dans le deuxième exemple, où Gemini met en forme le mot "transmitted" pour signaler qu'il est barré alors que ce n'est pas le cas dans la source. Le texte généré par Gemini ne laisse pas de doute vis-à-vis de l'aspect du texte dans la source et invente une intention de la part de l'auteur: "&lt;em&gt;In the second line of the body, the word 'transmitted' is crossed out in the original text, but the sentence is grammatically incomplete without it (or a similar verb). It is likely the author meant to replace it to avoid repetition with the word 'transmitting' appearing a few lines later but forgot to insert the new word.&lt;/em&gt;" Alors que cette erreur était plus facile à repérer, Dan Cohen nous dit pourtant encore une fois: "&lt;em&gt;Another perfect job.&lt;/em&gt;"&lt;/p&gt;
&lt;p&gt;Le coup de grâce à mon avis vient avec le troisième exemple. Gemini n'en propose pas de transcription complète, et génère, après quelques lignes, un message indiquant que le texte est illisible au-delà d'un certain point. Cela permet à Dan Cohen d'en conclure: "&lt;em&gt;Gemini does the right thing here: rather than venture a guess like a sycophantic chatbot, it is candid when it can’t interpret a section of the letter.&lt;/em&gt;" Personnellement, je m'étouffe en lisant ça, vu les erreurs déjà notées dans les deux exemples précédents. Au contraire de ce qu'affirme Dan Cohen, il n'y a pas de candeur ici, mais plutôt une effet pervers de ce que j'imagine être un calibrage du modèle en fonction de son taux de perplexité. Dans les deux premiers exemples, on peut imaginer que la perplexité du modèle face à certains passages difficiles conduit à la génération d'une note et/ou d'un insert entre crochets, mais n'empêche pas la génération d'une transcription fausse. Elle passe d'autant plus inaperçue que les explications générées en notes sont fausses et sonnent bien. On n'a donc pas affaire à un robot candide, mais à un chatbot arnaqueur. Et à mon avis il serait vraiment temps que ses utilisateurs l'intègrent, en ayant la main d'autant moins légère quand ils contrôlent ce que génèrent ces outils.&lt;/p&gt;
&lt;p&gt;Je n'ai pas encore lu le &lt;a href="https://generativehistory.substack.com/p/gemini-3-solves-handwriting-recognition"&gt;billet&lt;/a&gt; de Mark Humphries que je mentionnais tout au début, mais j'aurais peut-être l'occasion de revenir encore sur le sujet. A vrai dire, ce que je trouve vraiment vraiment dommage avec ces publications, issues du monde académique, qui contribuent à alimenter l'hystérie autour de l'IA générative, c'est qu'elle me donne l'impression que décidément ce n'est même pas de la part de la communauté scientifique que viendra le Salut. En tant que citoyenne et jeune chercheuse, cela m'inquiète beaucoup.  &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:precision_inedit"&gt;
&lt;p&gt;Je donne cette précision sur l'édition des biographies et des correspondances car elle me semble importante: Dan Cohen n'a pas pris des documents dont on est sûr qu'ils soient inédits. Etant donné que les modèles d'IA générative sont entraînés à partir de tout ce qui peut être trouvé sur le Web, cela veut dire que ces lettres ont peut-être d'une manière ou d'une autre, fait partie des lots utilisés pour l'entraînement. Par exemple, &lt;a href="https://foinse.ucc.ie/en/records/IE/BL/PP/BP/1/A/1/1/51?utm_source=dancohen&amp;amp;utm_medium=email&amp;amp;utm_campaign=the-writing-is-on-the-wall-for-handwriting-recognition"&gt;sur le site&lt;/a&gt; des Archives du University College of Cork, d'où est tirée la numérisation de la lettre de Boole, on trouve le texte suivant dans le champ description: "&lt;em&gt;Boole in Cork to Maryann. He is in a very depressed mood, life has become monotonous with only his work adding interest to the day. He enjoys playing the piano but 'it would be better with someone else to listen and to be listened to'. He is also very annoyed by [Cropers] dedicating his book to him without first asking for permission - 'I cannot help feeling that he has taken a great liberty' - and speaks in strong terms of [Cropers] 'pretensions to high morality'. He invites and urges Maryann to visit him as soon as their mother's health would allow. He feels the climate would do her good.&lt;/em&gt;" Ce sont des éléments de contexte qui peuvent aider, y compris un modèle, au moment de transcrire. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/025/#fnref:precision_inedit" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:standard_layout"&gt;
&lt;p&gt;Je ne dis pas "mise en page standard", parce que le phénomène qui est illustré par le troisième exemple, le fait de réécrire sur la même feuille après l'avoir tournée à 90°, correspond à une pratique qu'on retrouve au moins jusqu'au milieu du XXe siècle. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/025/#fnref:standard_layout" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:precision_error_tkb"&gt;
&lt;p&gt;Parmi les erreurs de Transkribus, on peut aussi noter l'utilisation d'un "&lt;a href="https://www.compart.com/en/unicode/U+0432"&gt;в&lt;/a&gt;" (le v cyrillique) pour transcrire le "B" de la côte du document, et d'un "&lt;a href="https://www.compart.com/en/unicode/U+0440"&gt;р&lt;/a&gt;" (le r cyrillique) pour transcrire le "P" qui suit. Ce sont des erreurs qui nous échappent quand on fait un contrôle visuel rapide, qui ne gêne pas la lecture par les humains, mais qui font baisser la précision calculée automatiquement puisque qu'un в n'est pas un B et un р n'est pas un P, ni d'ailleurs un p (see what I did here?). &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/025/#fnref:precision_error_tkb" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:lisible"&gt;
&lt;p&gt;Par lisible, je veux dire qu'on n'a pas besoin de savoir quelle était la phrase de départ pour comprendre ce qu'on aurait du lire dans les erreurs. J'admets par contre qu'en fonction de la familiarité avec le texte ou de la langue ou de la nature des erreurs, cette lisibilité peut varier. Si jamais vous trouvez quand même cette phrase illisible, il faut la lire comme ceci: "the hardest problem in digital humanities has finally been solved". Il y avait 1 inversion de lettres dans "&lt;em&gt;digital&lt;/em&gt;", une lettre manquante dans "&lt;em&gt;humanities&lt;/em&gt;", une lettre substituée par une autre dans "&lt;em&gt;finally&lt;/em&gt;", un lettre en trop dans "&lt;em&gt;been&lt;/em&gt;" et une séparation inappropriée dans "&lt;em&gt;solved&lt;/em&gt;". &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/025/#fnref:lisible" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>evaluation</category><category>French blog posts</category><category>Generative AI</category><category>HTR</category><category>Large Language Models</category><category>literature review</category><guid>https://alix-tz.github.io/phd/posts/025/</guid><pubDate>Fri, 28 Nov 2025 21:50:54 GMT</pubDate></item><item><title>024 - The messy backstage of a literature review</title><link>https://alix-tz.github.io/phd/posts/024/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;A few weeks ago, I began a thorough review of articles published in four digital humanities venues to track mentions of automatic text recognition and understand how, where, and why scholars use it. Although I wish I had started sooner in my doctoral journey, I stay positive holding on to the idea that "it's never too late." I learn a lot about Digital Humanities as a field of research and gain a better understanding of ATR's presence in the field.&lt;/p&gt;
&lt;p&gt;While catching up on our dissertation progress, I was telling Roch Delanney about the survey I'm conducting, my goals for it, and how I selected and sorted the articles. Roch suggested that I share my method more widely. It seems a little clumsy at times, but I am also able to use many different skills I have learned and sharpened over the years so I think it is indeed interesting to share a bit of my &lt;em&gt;cuisine&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Perimeter of the literature review&lt;/h3&gt;
&lt;p&gt;My literature review focuses on four publication venues. I think they are, collectively, representative of research in the Digital Humanities: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://academic.oup.com/dsh"&gt;&lt;em&gt;Digital Scholarship in the Humanities&lt;/em&gt;&lt;/a&gt; (DSH), which is presented by the Alliance of Digital Humanities Organizations (ADHO) as an international, peer-reviewed journal published by Oxford University Press on behalf of ADHO and the European Association for Digital Humanities (EADH). It was published under the title &lt;em&gt;Literary and Linguistic Computing: The Journal of Digital Scholarship in the Humanities&lt;/em&gt; until 2014. I counted a total of 174 volumes for a total of 1741 articles (excluding retracted articles, book reviews, editorials and committee reports) published since 1985 until the first half of 2025.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dhq.digitalhumanities.org/"&gt;&lt;em&gt;Digital Humanities Quarterly&lt;/em&gt;&lt;/a&gt; (DHQ) is an open-access peer-reviewed journal, probably more representative of research in North America. It is published by the Association for Computers and the Humanities (ACH). I counted a total of 790 articles published since its first issue in 2007. Most articles are in English.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href="https://jdmdh.episciences.org/"&gt;&lt;em&gt;Journal of Data Mining and Digital Humanities&lt;/em&gt;&lt;/a&gt; (JDMDH), is published by Episciences since 2017. Contrary to DHQ, its focus is more European-centric, and it has a special volume dedicated specifically to automatic text recognition (directed by Ariane Pinche and Peter Stokes). I found a total of 162 articles published in JDMDH, including the special volume on ATR.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lastly, the proceedings from the more recent &lt;em&gt;Computational Humanities Research&lt;/em&gt; (CHR) conferences (see the &lt;a href="https://2024.computational-humanities-research.org/"&gt;2024 conference proceedings&lt;/a&gt; for example) offer a perspective on research focused on more intensively computational methods in the Humanities. The conference is held annually since 2021. I found a total of 214 articles in the proceedings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Aside from DSH, that I can access thanks to the library of the University of Montréal, all the other journals are in open access. &lt;/p&gt;
&lt;h3&gt;Collecting the articles and their metadata&lt;/h3&gt;
&lt;p&gt;For JDMDH, articles are not centralized on the journal website but rather published on platforms like &lt;a href="https://hal.archives-ouvertes.fr/"&gt;HAL&lt;/a&gt; or &lt;a href="https://arxiv.org/"&gt;arXiv&lt;/a&gt; and sometimes &lt;a href="https://zenodo.org/"&gt;Zenodo&lt;/a&gt;. Getting an overview of the articles published in JDMDH is not straightforward, but it is possible to browse the articles per &lt;a href="https://jdmdh.episciences.org/browse/volumes"&gt;volumes&lt;/a&gt;. I opened and downloaded each article in each volume, as well as collected the article entries in Zotero using the Zotero connector. The process was cumbersome and required many clicks, but the variety of publishing platforms deterred me from writing a script to automate the downloading process.  &lt;/p&gt;
&lt;p&gt;CHR, on the other hand, was very easy to scrape, partly because there are only four volumes of proceedings so far. For each series of proceeding, the index of all articles is compatible with the batch import scenario of the Zotero connector. To collect the PDFs, I used a section of the HTML page and regular expressions to identify the links to the PDF files, creating a list of URLs. Finally, I used a Python script to download the PDFs to my computer.  &lt;/p&gt;
&lt;p&gt;For example, in &lt;a href="https://ceur-ws.org/Vol-2989/"&gt;https://ceur-ws.org/Vol-2989/&lt;/a&gt;, the &lt;code&gt;ul&lt;/code&gt; contains simple HTML elements pointing to the PDF files, such as: &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"CEURSESSION"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Presented papers&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"long_paper5"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"long_paper5.pdf"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"CEURTITLE"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Entity Matching in Digital Humanities Knowledge
      Graphs&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"CEURPAGES"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;1-15&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;br&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"CEURAUTHOR"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Juriaan Baas&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;,
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"CEURAUTHOR"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Mehdi M. Dastani&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;,
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"CEURAUTHOR"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Ad J. Feelders&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;All I had to do was copy and paste this entire list into a text editor (I like to use &lt;a href="https://www.sublimetext.com/"&gt;Sublime Text&lt;/a&gt; in such a situation). Then, I used a simple regular expression like &lt;code&gt;href=".+?"&lt;/code&gt; to select the value in the &lt;code&gt;a&lt;/code&gt; element, which contains the links to the PDF files. I kept only the selected text and then rebuilt the complete URL with a couple of replacements such as &lt;code&gt;href="&lt;/code&gt; -&amp;gt; &lt;code&gt;"https://ceur-ws.org/Vol-2989/&lt;/code&gt; and &lt;code&gt;"\n&lt;/code&gt; -&amp;gt; &lt;code&gt;",\n&lt;/code&gt;. At this point I just added square brackets around the selection, et voilà! I had a Python list ready to be passed to a script like the one below to download the files:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;list_of_urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"https://ceur-ws.org/Vol-2723/short8.pdf"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="s2"&gt;"https://ceur-ws.org/Vol-2723/long35.pdf"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="s2"&gt;"https://ceur-ws.org/Vol-2723/long44.pdf"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="c1"&gt;#...&lt;/span&gt;
                &lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;tqdm&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tqdm&lt;/span&gt; &lt;span class="c1"&gt;# it makes  progress bar so I know how long I can take to make a tea while the script runs&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tqdm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_urls&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status_code&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"/"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;-&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"/"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
        &lt;span class="c1"&gt;#print(filename)&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"wb"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Failed to download: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# This cool down is to be polite to the server&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I used a similar approach for downloading the articles from DHQ because the &lt;a href="https://dhq.digitalhumanities.org/index/title.html"&gt;Index of Titles&lt;/a&gt; lists all of the published articles on a single page. I first downloaded the HTML pages of the articles (DHQ publishes articles in HTML format as well as PDF). I also used regular expressions to extract the list of links and used a Python script to download the files.  &lt;/p&gt;
&lt;p&gt;Unfortunately, the Zotero connector only works on each article page individually, but not for batch-import on the index page. I investigated a bit to understand why it was so, and found that in the source code of each article page, there is a &lt;code&gt;span&lt;/code&gt; element identified with the class &lt;code&gt;Z3988&lt;/code&gt; that the Zotero connector uses to extract the metadata and create an entry in Zotero. In DHQ, these spans look like this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"Z3988"&lt;/span&gt; &lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"url_ver=Z39.88-2004&amp;amp;amp;ctx_ver=Z39.88-2004&amp;amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;amp;amp;rft.genre=article&amp;amp;amp;rft.atitle=Academics%20Retire%20and%20Servers%20Die%3A%20Adventures%20in%20the%20Hosting%20and%20Storage%20of%20Digital%20Humanities%20Projects&amp;amp;amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;amp;amp;rft.stitle=DHQ&amp;amp;amp;rft.issn=1938-4122&amp;amp;amp;rft.date=2023-05-26&amp;amp;amp;rft.volume=017&amp;amp;amp;rft.issue=1&amp;amp;amp;rft.aulast=Cummings&amp;amp;amp;rft.aufirst=James&amp;amp;amp;rft.au=James%20Cummings"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I understood recently, while discussing with Margot Mellet, that Z3988 is a reference to the &lt;a href="https://groups.niso.org/higherlogic/ws/public/download/14833/z39_88_2004_r2010.pdf"&gt;OpenURL Framework Standard (ISO Z 39.88-2004)&lt;/a&gt;, which is used by the Zotero connector. Also, I should note that such spans are not systematically used in online journals. JDMDH for example doesn't use them, and serves the metadata in a different way.  &lt;/p&gt;
&lt;p&gt;Since I had already downloaded all the articles from DHQ as HTML files, I wrote a simple Python script that found all of such spans for each downloaded article and aggregated them in a single, very simple HTML file. Then, I simply opened this page in my browser after emulating a local server&lt;sup id="fnref:python_server"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/024/#fn:python_server"&gt;1&lt;/a&gt;&lt;/sup&gt; (with a command like &lt;code&gt;python -m http.server&lt;/code&gt;), and I was able to use the Zotero connector to import all the articles in a single click. It was very satisfying! The only downside is that I couldn't collect the articles' abstracts because there weren't included in the spans.  &lt;/p&gt;
&lt;p&gt;DSH was different from the rest of the journals. Because of the longevity of the journal and the amount of articles it published, it was quite overwhelming. Unfortunately, it is a paywalled journal and I couldn't figure out how to make the proxy of the University of Montreal library work with my Python scripts and the command line. As a result, I had to manually download the articles,&lt;sup id="fnref:proxy_dsh"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/024/#fn:proxy_dsh"&gt;2&lt;/a&gt;&lt;/sup&gt; but only when they were relevant! Since DSH has a fairly good search engine that allows to do multi-keyword searches, I only downloaded articles matching my search criteria (143 in total).&lt;/p&gt;
&lt;p&gt;Additionally, I went through each of the 174 issues of DSH to batch-import the article references in Zotero. It was tedious but I figured I might be able to use these metadata for other projects in the future.  &lt;/p&gt;
&lt;h3&gt;Filtering the articles&lt;/h3&gt;
&lt;p&gt;For DHQ, JDMDH and CHR, I ran a keyword surch using the command &lt;a href="https://www.man7.org/linux/man-pages/man1/grep.1.html"&gt;&lt;code&gt;grep&lt;/code&gt;&lt;/a&gt; on the content of the articles. I didn't want to limit my search to the titles, abstract or keywords because I really wanted to include anecdotal mentions of automatic text recognition in my results.  &lt;/p&gt;
&lt;p&gt;To use grep, I created a file (pattern.txt) with the keywords I was looking for:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;HTR
OCR
text recognition
ATR
Transkribus
eScriptorium
automatic transcription
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then I converted the PDFs into text files using the command &lt;a href="https://man.archlinux.org/man/pdftotext.1.en"&gt;pdftotext&lt;/a&gt;. This was necessary because grep cannot search inside a PDF directly. I didn't need to do this conversion for DHQ, since I had download HTML files from that journal. &lt;/p&gt;
&lt;p&gt;The commands to search inside the PDFs of one of the journals would look like this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;ls&lt;span class="w"&gt; &lt;/span&gt;*.pdf&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;xargs&lt;span class="w"&gt; &lt;/span&gt;-n1&lt;span class="w"&gt; &lt;/span&gt;pdftotext&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# to convert PDFs to text files&lt;/span&gt;
grep&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;-w&lt;span class="w"&gt; &lt;/span&gt;-m5&lt;span class="w"&gt; &lt;/span&gt;-H&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;../pattern.txt&lt;span class="w"&gt; &lt;/span&gt;*.txt&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# to search for the keywords in the text files and display the first 5 matches&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After controlling how grep matched the keywords, I used &lt;code&gt;grep -l -f ../pattern.txt *.txt&lt;/code&gt; to list the files that matched the keywords. This list was used to sort the documents into two folders, according to whether or not they matched my research.&lt;/p&gt;
&lt;p&gt;In the case of DSH, I directly used the search engine to combine the keywords, using the "OR" operator. I set the full text of the articles as the scope of my research: &lt;a href="https://academic.oup.com/dsh/search-results?allJournals=1&amp;amp;f_ContentType=Journal+Article&amp;amp;fl_SiteID=5447&amp;amp;cqb=[{%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22automatic%20transcription%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22transkribus%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22text%20recognition%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22escriptorium%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22OCR%22}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22HTR%22}]}]&amp;amp;qb={%22_text_1-exact%22:%22automatic%20transcription%22,%22qOp2%22:%22OR%22,%22_text_2-exact%22:%22transkribus%22,%22qOp3%22:%22OR%22,%22_text_3-exact%22:%22text%20recognition%22,%22qOp4%22:%22OR%22,%22_text_4-exact%22:%22escriptorium%22,%22qOp5%22:%22OR%22,%22_text_5%22:%22OCR%22,%22qOp6%22:%22OR%22,%22_text_6%22:%22HTR%22}&amp;amp;page=1"&gt;https://academic.oup.com/dsh/search-results?allJournals=1&amp;amp;f_ContentType=Journal+Article&amp;amp;fl_SiteID=5447&amp;amp;cqb=[{%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22automatic%20transcription%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22transkribus%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22text%20recognition%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22escriptorium%22,%22exactMatch%22:true}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22OCR%22}]},{%22condition%22:%22OR%22,%22terms%22:[{%22filter%22:%22_text_%22,%22input%22:%22HTR%22}]}]&amp;amp;qb={%22_text_1-exact%22:%22automatic%20transcription%22,%22qOp2%22:%22OR%22,%22_text_2-exact%22:%22transkribus%22,%22qOp3%22:%22OR%22,%22_text_3-exact%22:%22text%20recognition%22,%22qOp4%22:%22OR%22,%22_text_4-exact%22:%22escriptorium%22,%22qOp5%22:%22OR%22,%22_text_5%22:%22OCR%22,%22qOp6%22:%22OR%22,%22_text_6%22:%22HTR%22}&amp;amp;page=1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In both cases, the search was not case sensitive, in order to catch a maximum of occurrences of keywords like "automatic text recognition" or "Text Recognition" or "text recognition", etc. However, it meant that sometimes I found false positives: "democracy" often matches with "ocr", so does "theatre" with "atr". Since DSH's search engine returns the match in context, I was able to ignore these false positives. For the other journals, I had to manually check where the matches were. Usually, I combined this control with the next step of my investigation.  &lt;/p&gt;
&lt;h4&gt;Hits per journal&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;JDMDH: 47 hits (out of 162 articles)&lt;/li&gt;
&lt;li&gt;DHQ: 93 hits (out of 790 articles)&lt;/li&gt;
&lt;li&gt;DSH: 143 relevant hits (out of 1741 articles)&lt;/li&gt;
&lt;li&gt;CHR: 65 hits (out of 214 articles)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;em&gt;Dépouillement&lt;/em&gt; and analysis&lt;/h3&gt;
&lt;p&gt;To this date, I am still in the process of reading the articles and taking notes on the occurrences of my keywords. &lt;/p&gt;
&lt;p&gt;I use Zotero to keep track of the articles I read and to confirm whether they are false positives. Sometimes, I leave out articles that are irrelevant, even if they mention a keyword I was looking for. For example, &lt;a href="https://doi.org/10.1093/llc/fqac089"&gt;Liu &amp;amp; Zhu (2023)&lt;/a&gt;&lt;sup id="fnref:liu_zhu_2023"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/024/#fn:liu_zhu_2023"&gt;3&lt;/a&gt;&lt;/sup&gt; contains the string "OCR" but it only appears in a title in their bibliography, for work they refer to in a context where OCR is not relevant to their argument. With tags in Zotero, I clearly identify such articles as "to be left out" from my analysis, but I don't remove them from the collection.  &lt;/p&gt;
&lt;p&gt;I use different tags to identify the various occurrences of the technology in the articles. For example, I distinguish between firsthand applications of ATR and the reuse of data produced by ATR before the experimentation presented by the authors. Typically, there are many mentions of documents that were OCRed by libraries and used by scholars to conduct their research. Overall, with this analysis, I am trying to add more depth to the observations made by &lt;a href="https://doi.org/10.48550/arXiv.2304.13530"&gt;Tarride et al (2023)&lt;/a&gt;&lt;sup id="fnref:tarride_et_al_2023"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/024/#fn:tarride_et_al_2023"&gt;4&lt;/a&gt;&lt;/sup&gt; in which they pragmatically considered three situations leading to the use of ATR: 1) for the production of digital editions; 2) for the production of large searchable text corpora; and 3) for the production of non-comprehensive transcriptions to feed knowledge bases. However, it is difficult to elaborate definitive categories before I am done processing all the collected articles.  &lt;/p&gt;
&lt;p&gt;Due to the large number of articles to be analyzed, I have continued to use the grep command to quickly review the content of articles and speed up my sorting process. For example, I am more interested in firsthand usages of ATR, want to be able to quickly identify non relevant mentions of my keywords as was the case in Liu &amp;amp; Zhu (2023). The command &lt;code&gt;grep -i -w -C 5 -H -f ../pattern.txt *.txt &amp;gt; grep_out&lt;/code&gt; allows me to generate a file, grep_out, in which, for each time a keyword is matched in a document, five lines of context are displayed before and after the match, as well as the name of the file. I still have to read the abstracts and parts of the articles to clearly understand in which contexts the automatic text recognition technologies are used. However, this is an effective method for quickly sorting through the articles.&lt;/p&gt;
&lt;p&gt;I'm looking forward to sharing the results of this analysis in my dissertation! &lt;/p&gt;
&lt;!-- FOOTNOTES ---&gt;

&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:python_server"&gt;
&lt;p&gt;This emulation is necessary to allow the Zotero connector to work properly. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/024/#fnref:python_server" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:proxy_dsh"&gt;
&lt;p&gt;I want to specify here that it was not by lack of reading documentations on proxies and requests. Unable to find a straightforward solution, unsure if it was even something that the UdeM proxy allowed, and because I would have still needed to write additional scripts afterwards, I decided that it would take just as long to do it manually (about 2-3 hours). &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/024/#fnref:proxy_dsh" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:liu_zhu_2023"&gt;
&lt;p&gt;Liu, Lei, and Min Zhu. "Bertalign: Improved Word Embedding-Based Sentence Alignment for Chinese–English Parallel Corpora of Literary Texts." &lt;em&gt;Digital Scholarship in the Humanities&lt;/em&gt; 38, no. 2 (June 1, 2023): 621–34. &lt;a href="https://doi.org/10.1093/llc/fqac089"&gt;https://doi.org/10.1093/llc/fqac089&lt;/a&gt;. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/024/#fnref:liu_zhu_2023" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:tarride_et_al_2023"&gt;
&lt;p&gt;Tarride, Solène, Mélodie Boillet, and Christopher Kermorvant. "Key-Value Information Extraction from Full Handwritten Pages." arXiv, April 26, 2023. &lt;a href="https://doi.org/10.48550/arXiv.2304.13530"&gt;https://doi.org/10.48550/arXiv.2304.13530&lt;/a&gt;. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/024/#fnref:tarride_et_al_2023" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>HTR</category><category>literature review</category><category>OCR</category><category>survey</category><guid>https://alix-tz.github.io/phd/posts/024/</guid><pubDate>Sat, 21 Jun 2025 19:15:27 GMT</pubDate></item><item><title>023 - Writing a PhD manuscript with Markdown and Quarto</title><link>https://alix-tz.github.io/phd/posts/023/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;The deadline for finishing the dissertation is approaching. And there is still so much to do! This is one of the main reasons why this research blog has been quiet for the last few months, even though there are many topics I would like to write about. &lt;/p&gt;
&lt;p&gt;But I guess I can take a short break from time to time and go with the flow of writing a blog post in one sitting. Who knows, maybe I'll do a few more before it's time to turn in my dissertation. I want to talk about my writing setup because it is something I have thought about a lot, trying to find the best compromise. &lt;/p&gt;
&lt;p&gt;Writing my dissertation in Microsoft Word has never been an option, although I do use Google Docs from time to time to get quick feedback from my supervisors. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.latex-project.org/"&gt;LaTeX&lt;/a&gt; may seem like an obvious choice to some of my fellow PhD writers, but I usually limit my use of LaTeX to &lt;a href="https://www.overleaf.com"&gt;Overleaf&lt;/a&gt;, an online LaTeX editor. On the one hand, I didn't necessarily want to install LaTeX locally for the time being, and on the other hand, I couldn't imagine writing a whole dissertation using Overleaf, because working in my browser can be distracting, and because it would require that I always have access to the Internet to work. To be honest, I mostly didn't want to use LaTeX in the first place because I find the syntax too distracting when I'm writing. It's super useful for getting good control over the layout of the document for the final version of the manuscript, but it's not convenient to work with while I'm formulating ideas and arguments.&lt;/p&gt;
&lt;p&gt;I will probably use LaTeX to prepare the final version of the manuscript, but I wanted to use something lighter to structure my document, but easily convertible to LaTeX down the road. &lt;/p&gt;
&lt;p&gt;And I am a big fan of Markdown.&lt;/p&gt;
&lt;p&gt;Markdown has a syntax that is light enough not to be too distracting - I use it all the time when taking notes anyway, so it is fully part of my writing reflexes. Also, in the context of writing my dissertation, I think of Markdown as text that I can easily copy and paste into a Google document when I need feedback, without losing formatting and without compromising readability in Google Docs. I've seen some LaTeX copy-pasted into Google Docs for supervisor feedback, and I don't think it would work for me. &lt;/p&gt;
&lt;p&gt;In addition to Markdown, I wanted to be able to use a modular approach to building my manuscript. A modular approach means having several smaller text files that are eventually merged into a single master document. LaTeX also relies on modularity with commands like &lt;code&gt;\include{}&lt;/code&gt;. Modularity is important because in a very long text document it is easy to get lost between inline comments, draft passages, and finished paragraphs. There's also the risk of accidentally deleting passages. With a modular structure, it will also be easier to move paragraphs around as I progress. Also, my manuscript is versioned with Git and synchronized with a private GitHub repository, and modularity makes versioning much easier.&lt;/p&gt;
&lt;p&gt;Instead of programming my own manuscript builder - yes, that was my first impulse - I took a closer look at the documentation for &lt;a href="https://quarto.org/"&gt;Quarto&lt;/a&gt;, which I've been using for a little over a year to create slides and websites for the courses I teach. Quarto offered me a solution on a silver platter, because it supports building &lt;a href="https://quarto.org/docs/reference/projects/books.html"&gt;books&lt;/a&gt; with Markdown, which is close enough to a phD thesis. &lt;/p&gt;
&lt;p&gt;Quarto implements a single-source publishing paradigm and acts as a shell around &lt;a href="https://pandoc.org/"&gt;pandoc&lt;/a&gt;, which allows for swift conversion from one format to another, including from Markdown to LaTeX. I can split the document into multiple smaller Markdown files, and use my book's config file to specify the order in which the Markdown files are aggregated. Quarto's Markdown implementation includes some cool stuff from pandocs, including citation and cross-reference management. It's really worth taking a look at the documentation.&lt;/p&gt;
&lt;p&gt;So with Quarto, I can write my dissertation as a series of smaller Markdown files, and end up with a master .md file, a .tex file ready to import into Overleaf, or even an already parsed PDF file generated with &lt;a href="https://quarto.org/docs/output-formats/pdf-engine.html"&gt;tinytex&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Quarto is not a text editor, it is simply a processor that starts with a set of markdown files and a config file, and then builds one or more outputs. To write, I use Visual Studio Code and have a &lt;code&gt;quarto preview&lt;/code&gt; command running in the background. For now, it just produces an HTML preview that I see in my browser. When I'm closer to a stable version of the manuscript, I'll start working with PDF output.&lt;/p&gt;
&lt;p&gt;The syntax for some of the more specific Markdown features in Quarto is more complex than I am used to, so I still have to look at the documentation from time to time. But I am getting the hang of it, and I use a cheat sheet for the features I use more often. &lt;/p&gt;
&lt;p&gt;Pandoc's Markdown support lets you apply classes to entire paragraphs or inline portions of text. This is useful because it has allowed me to create some CSS transformations with classes like "draft" or "missing-information" to keep track of passages I need to rewrite, or blocks where I need to get away from my text editor and go back to my notes (usually in &lt;a href="https://www.zotero.org/"&gt;Zotero&lt;/a&gt;). I find it super useful to avoid (at least as much as possible) falling into loopholes that distract me from actually writing. It's more efficient for my time management to divide my time between actual writing sessions and other sessions where I work on improving the drafty passages or doing the research I'm missing to illustrate an argument. &lt;/p&gt;
&lt;p&gt;Another use of inline classes is to keep track of concepts or specific terms that I could include in a glossary or at least a list of acronyms. By keeping track of them directly in the text, I can automate the generation of these sections. Some might say that this is the kind of thing I could do with &lt;a href="https://tei-c.org/release/doc/tei-p5-doc/en/html/index.html"&gt;TEI XML&lt;/a&gt;- I agree, since this is semantic annotation. But as I said, I wanted a lightweight syntax, and I really like Markdown.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;EDIT from June 20, 2025:&lt;/strong&gt; I feel the need to add a precision a few months after this original post: while I did like my set up with Markdown and Quarto to get started on writing my dissertation, I eventually switched to the good old LaTeX. Quarto/Markdown simply lacked too many features for what I wanted to do.&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Part of the problem came from the fact that custom annotations that turn into spans with custom classes during a Markdown-to-HTML transformation scenario were not converted into anything in LaTeX and were therefore lost. For example, I would have needed to manage the glossary and acronym handler afterwards, only once I was done with Markdown and fully switched to LaTeX. Rather than writing my own preprocessing script to find a solution to this problem (as far as I could see, pandoc does not offer any option to map markdown spans to custom LaTeX commands), I figured swithing to writing in LaTeX directly made more sense: there was no point in pushing too far the complications.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Also, I really wanted to be able to use the &lt;code&gt;todo&lt;/code&gt; package from LaTeX to keep track of feedback, side notes and questions I had for myself while writing. With this package, they are visible in the PDF output, which is useful also when I share my text with other people.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Lastly, Roch Delanney greatly facilitated this switch by sharing his LaTeX template with me. It was easy to start from the setup he created with Robert Alessi and to add my own configuration and customization. Their template was much more pure than templates that can be found on Overleaf, on top of being very well documented. It was great to keep things simple: I don't import any package that I don't actually need.&lt;/em&gt;&lt;/p&gt;</description><category>markdown</category><category>quarto</category><guid>https://alix-tz.github.io/phd/posts/023/</guid><pubDate>Tue, 18 Feb 2025 05:00:00 GMT</pubDate></item><item><title>022 - McCATMuS #5 - Training models</title><link>https://alix-tz.github.io/phd/posts/022/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;Last week, I visited Rimouski in the Bas-Saint-Laurent region of Québec, along the South-eastern bank of the St Laurent river. I was invited to contribute to discussions around the &lt;a href="https://nouvellefrancenumerique.info/"&gt;Nouvelle-France Numérique project&lt;/a&gt;, and I took this opportunity to &lt;a href="https://inria.hal.science/hal-04706828"&gt;present&lt;/a&gt; HTR-United, CATMuS as well as preliminary results on training a McCATMuS model. In preparation for this presentation, I conducted a series of tests on the two first models I trained. Today, this blog post gives me a space to discuss these tests and their results in more details.&lt;/p&gt;
&lt;p&gt;The Kraken McCATMuS models were not directly trained on the HuggingFace dataset I introduced in my &lt;a href="https://alix-tz.github.io/phd/posts/022/021/"&gt;previous post&lt;/a&gt;, but rather on ARROW files created with the same ALTO XML files used to create the HuggingFace dataset. At the beginning of September, I wrote a Python script which reproduces the split of ALTO XML files into the train, validation and test sets, and which applies the same type of filtering of lines and modifications as I previously presented. Instead of generating the PARQUET files for HuggingFace, it simply creates alternative &lt;code&gt;.catmus_arrow.xml&lt;/code&gt; files and three listings of these files, ready to be served to a &lt;a href="https://kraken.re/4.3.0/ketos.html#binary-datasets"&gt;&lt;code&gt;ketos compile&lt;/code&gt;&lt;/a&gt; command&lt;sup id="fnref:compile"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/022/#fn:compile"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I used Kraken 4.3.13 to train the models on Inria's computation server because I've had dependency issues with Kraken 5 and haven't fixed them yet. The first model I trained strictly followed the train/validation split thanks to the &lt;a href="https://github.com/mittagessen/kraken/blob/cdfb923eba8d7dba10b6f32fb73bdf1e355aaf74/kraken/ketos/recognition.py#L129C16-L129C30"&gt;&lt;code&gt;--fixed-splits&lt;/code&gt; option&lt;/a&gt;. After 60 epochs, the model plateaued at 79.9% of character accuracy. When applied to the test set, this accuracy remained at 78.06%, a mere two points drop.&lt;/p&gt;
&lt;p&gt;I trained a second model using the same parameters&lt;sup id="fnref:params"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/022/#fn:params"&gt;2&lt;/a&gt;&lt;/sup&gt; but without the &lt;code&gt;--fixed-splits&lt;/code&gt; option, allowing Kraken to shuffle the train set and the validation set into a 90/10 split (the test set was left untouched however). This time, the training lasted 157 epochs before stopping, with the best model scoring with an accuracy of 92.8% on the validation set. When applied to the test set however, the model lost 7 points of accuracy (85.24%).&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://alix-tz.github.io/phd/images/mccatmus_v1_entra%C3%AEnement_fixedsplits.png" alt="Learning curve for the model trained on the fixed split."&gt;
    &lt;figcaption&gt;Learning curve (Character and Word Accuracies) for the model trained on the fixed "feature"-based split between train and validation.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://alix-tz.github.io/phd/images/mccatmus_v1_entra%C3%AEnement.png" alt="Learning curve for the model trained on the non-fixed split."&gt;
    &lt;figcaption&gt;Learning curve (Character and Word Accuracies) for the model trained on the random split between train and validation.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Although disappointing, this was consistent with the observations made when training the CATMuS Medieval model:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;As anticipated, the "General" split exhibits lower CER, given the absence of out-of-domain documents, whereas the "Feature"-based split surpasses 10%. This higher score presents an intriguing challenge for developing more domain-specific models that consider factors such as script type and language.&lt;/em&gt; (from &lt;a href="https://univ-paris8.hal.science/hal-04453952v1"&gt;Thibault Clérice, Ariane Pinche, Malamatenia Vlachou-Efstathiou, Alix Chagué, Jean-Baptiste Camps, et al.. CATMuS Medieval: A multilingual large-scale cross-century dataset in Latin script for handwritten text recognition and beyond. 2024 International Conference on Document Analysis and Recognition (ICDAR), 2024, Athens, Greece. ⟨hal-04453952⟩&lt;/a&gt; p. 15)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, the drop in accuracy observed on the test set is, as suggested in &lt;em&gt;Clérice et al, 2024&lt;/em&gt;, likely due to the fact that with a fixed-split, the model is both validated and tested against out-of-domain hands and documents (although the documents differ in the two sets). On the other hand, the model trained with a random split is validated against known hands and documents, but tested on out-of-domain examples.&lt;/p&gt;
&lt;p&gt;The test set contains transcriptions of printed, typewritten and handwritten texts, covering all centuries. Limiting ourselves to only one accuracy score obtained on the whole test set would tell us very little about the model's capacity and its limitations. This is why I divided the test set into several smaller test sets based on the century of the documents and/or on the main type of writing present in the documents. For documents spanning over several centuries, I used the most represented century.&lt;/p&gt;
&lt;p&gt;I only used the McCATMuS trained on the random split for these tests, because the accuracy of the other one was too low for the results to be meaningful. Instead of only testing McCATMuS, I also ran the Manu McFrench V3 and McFondue on the McCATMuS test set. They are two generic models trained on similar data (although with no or different normalization approaches).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;Test set..............&lt;/th&gt;
&lt;th style="text-align: left;"&gt;...McCATMuS...&lt;/th&gt;
&lt;th style="text-align: center;"&gt;...Manu McFrench V3...&lt;/th&gt;
&lt;th style="text-align: right;"&gt;...McFondue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;All...................&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...85.24...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;91.17&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...76.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Handwritten...........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...78.72...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;89.40&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...75.17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Print.................&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...&lt;strong&gt;96.37&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...94.15...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...78.30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Typewritten...........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...90.93...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;92.69&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...58.13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;17th cent.............&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...&lt;strong&gt;87.27&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...86.39...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...72.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;18th cent.............&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...88.65...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;94.21&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...81.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;19th cent.............&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...79.81...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;93.70&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...75.46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;20th cent.............&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...74.92...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;86.52&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...56.74&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;21st cent.............&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...73.86...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;90.20&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...68.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;(HW) 17th cent........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...58.69...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;64.83&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...&lt;em&gt;64.26&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;(HW) 18th cent........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...85.38...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;93.35&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...80.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;(HW) 19th cent........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...79.81...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;93.70&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...75.46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;(HW) 20th cent........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...63.02...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;82.23&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...55.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;(HW) 21st cent........&lt;/td&gt;
&lt;td style="text-align: left;"&gt;...73.86...&lt;/td&gt;
&lt;td style="text-align: center;"&gt;...&lt;strong&gt;90.20&lt;/strong&gt;...&lt;/td&gt;
&lt;td style="text-align: right;"&gt;...68.04&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- add plot? --&gt;

&lt;p&gt;I was initially surprised by the consistent margin Manu McFrench had over McCATMuS, considering it was trained on less data (73.9K + 8.8K lines, against the 106K + 5.8K lines) which had not been harmonized to follow the same transcription rules. However, these scores are actually biased in favor of Manu McFrench because several of the documents included in the McCATMuS test set were also used in Manu McFrench's train set. Even though this is not true for all documents, it concerns almost half of the test set. It might also be the case for McFonddue, but this model scores higher than McCATMuS in only one instance (handwritten documents from the 17th century). Creating a new test set, with documents that are not present in any of the train sets but follow the CATMuS guidelines, would be a good way to confirm this bias.&lt;/p&gt;
&lt;p&gt;Additionally, I detected an issue in one of the datasets used in the test set: &lt;code&gt;FoNDUE_Wolfflin_Fotosammlung&lt;/code&gt; contains some lines of faulty transcriptions, resulting from automatic text recognition, which most certainly cause an inaccurate evaluation of all three models.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;A couple of examples of the faulty transcriptions, along with their CER they generate when compared to what would be a correct transcription (the CER is generated with &lt;a href="https://github.com/WHaverals/CERberus"&gt;CERberus&lt;/a&gt;):&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;Line image&lt;/th&gt;
&lt;th style="text-align: right;"&gt;Faulty transcription&lt;/th&gt;
&lt;th style="text-align: right;"&gt;Correct transcription&lt;/th&gt;
&lt;th style="text-align: center;"&gt;Faulty CER would be&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;&lt;img alt='text line images reading, in print, "COLLECTION HANFSTAENGL LONDON"' src="https://alix-tz.github.io/phd/images/fotosammlung_error_example1.jpg"&gt;&lt;/td&gt;
&lt;td style="text-align: right;"&gt;"CSTITHER, KIESERMAEAER AogS."&lt;/td&gt;
&lt;td style="text-align: right;"&gt;"COLLECTION HANFSTAENGL LONDON"&lt;/td&gt;
&lt;td style="text-align: center;"&gt;89.29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;&lt;img alt='text line image reading, in print, "NATIONAL GALLERY"' src="https://alix-tz.github.io/phd/images/fotosammlung_error_example2.jpg"&gt;&lt;/td&gt;
&lt;td style="text-align: right;"&gt;"PEcLioL."&lt;/td&gt;
&lt;td style="text-align: right;"&gt;"NATIONAL GALLERY"&lt;/td&gt;
&lt;td style="text-align: center;"&gt;175.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have planned to manually control this dataset and update the McCATMuS dataset accordingly. I don't know yet how many lines are affected.&lt;/p&gt;
&lt;p&gt;The better accuracy of the Manu McFrench model is not just a product of the biases in the test set. I had the occasion to apply it to two documents, one from the 17th century and one from the 20th century. In both cases, Manu McFrench's transcription seemed more likely to be correct than McCATMuS's. This has led me to compare the training parameters used for both models and to start a third training experiment using Manu McFrench's parameters. In this case, the batch size is reduced to 16 (as opposed to 32) and the Unicode normalization follows &lt;a href="https://unicode.org/reports/tr15/#Compatibility_Composite_Figure"&gt;NFKD instead of NFD&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If the results of this third training are consistent with the previous experiments, it will be interesting to see if adding more data to the training set will improve the results. Also, I have yet to test the model in a situation of finetuning.&lt;/p&gt;
&lt;p&gt;As said at the beginning of this post, these results are preliminary, so I hope to have more to share in the coming weeks.&lt;/p&gt;
&lt;!-- footnotes --&gt;

&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:compile"&gt;
&lt;p&gt;The command looks like this: cat "./list_of_paths.txt" | xargs -d "\n" ketos compile -o "./binary_dataset.arrow" --random-split .0 .0 1.0 -f alto. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/022/#fnref:compile" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:params"&gt;
&lt;p&gt;The configuration of Kraken for training these two model relies on the default network architecture, on a NFD Unicode normalization, a learning rate of 0.0001 (1e&lt;sup&gt;-4&lt;/sup&gt;), batch size of 32, padding of 16 (default value), and applies augmentation (&lt;code&gt;--augment&lt;/code&gt;). The &lt;code&gt;--fixed-splits&lt;/code&gt; option is used for the first model. Following Kraken's default behavior, the training stops when the validation loss does not decrease for 10 epochs (early stops); this prevents the model from overfitting, which is confirmed when looking at the accuracy score of the intermediary models on the test set (orange line on the graphs). The training is done on a GPU. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/022/#fnref:params" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>CATMuS</category><category>datasets</category><category>HTR</category><guid>https://alix-tz.github.io/phd/posts/022/</guid><pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate></item><item><title>021 - McCATMuS #4 - Cleaning data, collection metadata</title><link>https://alix-tz.github.io/phd/posts/021/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;Preparing the data for CATMuS would certainly have taken much more time had I not been able to benefit from Thibault Clérice's experience with CATMuS Medieval. Not only was I able to build on the workflow he set up when he built it, but I also relied heavily on his scripts to parse and build the final dataset into &lt;a href="https://parquet.apache.org/"&gt;PARQUET&lt;/a&gt; files that were pushed to HuggingFace. Most of these steps are described in &lt;a href="https://univ-paris8.hal.science/hal-04453952v1"&gt;Thibault Clérice, Ariane Pinche, Malamatenia Vlachou-Efstathiou, Alix Chagué, Jean-Baptiste Camps, et al.. CATMuS Medieval: A multilingual large-scale cross-century dataset in Latin script for handwritten text recognition and beyond. 2024 International Conference on Document Analysis and Recognition (ICDAR), 2024, Athens, Greece&lt;/a&gt;, presented at the &lt;a href="https://icdar2024.net/"&gt;ICDAR&lt;/a&gt; conference in Athens in a few days.&lt;/p&gt;
&lt;p&gt;For McCATMuS, I started by downloading all the datasets (keeping track of the official releases) then I manually reorganized all the datasets so that the transcription and images were always under &lt;code&gt;{dataset_repo}/data/{sub_folder}&lt;/code&gt;, which made later manipulation easier. Based on the notes I took while filtering the datasets, and after generating a character table for each dataset with &lt;a href="https://github.com/PonteIneptique/choco-mufin"&gt;Chocomufin&lt;/a&gt;, I created several conversion tables to harmonize the transcription. The conversions are a mix of single character or multiple character replacements (&lt;code&gt;[&lt;/code&gt; and  &lt;code&gt;[[?]]&lt;/code&gt;) and more or less sophisticated replacements based on regular expressions (&lt;code&gt;#r#«&lt;/code&gt;).&lt;sup id="fnref:chocomufin"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/021/#fn:chocomufin"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Here is a sample of the Chocomufin conversion table used for the LECTAUREP datasets. If the character is replaced by itself, it remains unchanged in the dataset, while replacing it allows either to remove a character from the dataset (the &lt;code&gt;¥&lt;/code&gt;) or to harmonize its transcription with the CATMuS guidelines (see &lt;code&gt;œ&lt;/code&gt; and &lt;code&gt;°&lt;/code&gt; for example).&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="nc"&gt;char&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;replacement&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;codepoint&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mufidecode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="k"&gt;order&lt;/span&gt;
&lt;span class="n"&gt;#r&lt;/span&gt;&lt;span class="err"&gt;#«&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;Repl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;extra&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;space&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;before&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;LEFT&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;POINTING&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;DOUBLE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ANGLE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;QUOTATION&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MARK&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;""""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;AB&lt;/span&gt;&lt;span class="p"&gt;,,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;#r&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;»&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;Repl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;extra&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;space&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;before&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;RIGHT&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;POINTING&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;DOUBLE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ANGLE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;QUOTATION&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MARK&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;""""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;BB&lt;/span&gt;&lt;span class="p"&gt;,,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;[?&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nf"&gt;replace&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;[?&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;⟦⟧&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="err"&gt;⟦⟧&lt;/span&gt;&lt;span class="p"&gt;,,,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;?&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nf"&gt;replace&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;?&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;⟦⟧&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="err"&gt;⟦⟧&lt;/span&gt;&lt;span class="p"&gt;,,,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="nf"&gt;RIGHT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PARENTHESIS&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt;&lt;span class="mi"&gt;0029&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt;
&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;006&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;É&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;CAPITAL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;WITH&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ACUTE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;É&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;C9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0061&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="ss"&gt;","&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;COMMA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;","&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;002&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;","&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0065&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;CIRCUMFLEX&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ACCENT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;005&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;œ&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LIGATURE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;OE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;oe&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0153&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;oe&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="err"&gt;̂&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;COMBINING&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;CIRCUMFLEX&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ACCENT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="err"&gt;̂&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0302&lt;/span&gt;&lt;span class="p"&gt;,,&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;CAPITAL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0057&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="err"&gt;°&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;DEGREE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;SIGN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;B0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="err"&gt;¥&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;YEN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;SIGN&lt;/span&gt;&lt;span class="p"&gt;,,&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;A5&lt;/span&gt;&lt;span class="p"&gt;,,&lt;/span&gt;
&lt;span class="n"&gt;½&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;VULGAR&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;FRACTION&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ONE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;HALF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;BD&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;H&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0068&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0072&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;æ&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;AE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ae&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;00E6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ae&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;ȼ&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;LATIN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SMALL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;LETTER&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;WITH&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;STROKE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;023&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="err"&gt;∟&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nf"&gt;RIGHT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ANGLE&lt;/span&gt;&lt;span class="p"&gt;,,&lt;/span&gt;&lt;span class="mi"&gt;221&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;UNKNOWN&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It wasn't possible to use a single conversion table for all the datasets because some had different transcription approaches. While replacing  &lt;code&gt;¬&lt;/code&gt; with &lt;code&gt;-&lt;/code&gt; could, in principle, be used for each dataset, normalizing the way corrections and uncertainties were transcribed was another story. For example, in some of the CREMMA datasets, &lt;code&gt;&amp;gt;&amp;lt;&lt;/code&gt; is used to signal a crossed word, while in other datasets &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; is used. So replacing &lt;code&gt;&amp;gt;&lt;/code&gt; with &lt;code&gt;⟦&lt;/code&gt; and &lt;code&gt;&amp;lt;&lt;/code&gt; with &lt;code&gt;⟧&lt;/code&gt; in &lt;code&gt;&amp;gt;hello&amp;lt;&lt;/code&gt; meant that in some cases we would successfully get &lt;code&gt;⟦hello⟧&lt;/code&gt;, while in other cases we would end up with &lt;code&gt;⟧hello⟦&lt;/code&gt;. There are a few documents where I had to manually intervene in the XML file to fix the transcription. In such cases, I fork the dataset repository to keep track of the corrected version of the ground truth or I push the correction back into the original dataset to create a new, more consistent version.&lt;/p&gt;
&lt;p&gt;In general, the converted dataset is saved as &lt;code&gt;.catmus.xml&lt;/code&gt; files, which allows us to keep track of the original ground truth and easily adjust the conversion table later if necessary afterwards.&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://alix-tz.github.io/phd/posts/19/"&gt;second post&lt;/a&gt; of this series, I mentioned that "&lt;em&gt;the CATMuS guidelines can (should?) be used as a reference point&lt;/em&gt;" and that "&lt;em&gt;if a project decides to use a special character to mark the end of each paragraph, then in order to create a CATMuS-compatible version of the dataset, I should only have to replace or remove that character. In such cases, the special character that was chosen should be unambiguous and the rule should be explicitly presented&lt;/em&gt;." Providing a Chocomufin conversion table along with a dataset that uses project-specific guidelines would be an excellent practice to ensure that the dataset is indeed compatible with CATMuS.&lt;/p&gt;
&lt;p&gt;Once all the &lt;code&gt;.catmus.xml&lt;/code&gt; files were ready, I created a new metadata table for McCATMuS listing all the subdirectories under each dataset's "data" folder. This table was used as a basis to start collecting additional metadata at the document level rather than at dataset level, like the language used in the source or the type of writing (printed, handwritten or typewritten). Working at the document level is important because some dataset contain different types of writing and/or are multilingual. In some cases, when a document would mix different languages and/or different types of writing in the source, if the distinction could be made at the image level, I manually sorted them and created two different subfolders. This is what I did in the "Memorials for Jane Lathrop Stanford" dataset, for example: the subfolder "PageX-LettreX" mixed typewritten and handwritten letters, so I sorted them into "PageX-LettreX-handwritten" and "PageX-LettreX-typewritten" in order to have the most accurate metadata possible.&lt;/p&gt;
&lt;p&gt;Other metadata included the assignment of a call number (or shelf mark) for each source represented in the datasets. In some cases a call number may apply to multiple subfolders, but in most cases, each subfolder is de facto a different document. Retrieving the call number is useful for several reasons: it allows for an accurate assessment of the diversity of documents in McCATMuS, it allows for a document to be associated with additional metadata found in its institution's catalog, or the list of call numbers can be used during benchmarking or production to check whether a document is known to the models trained on that dataset, thus explaining potentially higher accuracy scores.&lt;/p&gt;
&lt;p&gt;In the few cases where the source used to build the ground truth did not have a corresponding call number, I simply made one up, keeping "nobs_" as a signal that it was a made-up call number. Thus, if "cph_paris_tissage_1858/" in "timeuscorpus" is now associated with its corresponding call number at the Paris archive center (Paris, AD75, D1U10 386), CREMMAWiki's "batch-04", which is composed of documents we created for the project, is associated with a made-up call number: "nobs_cremma-wikipedia_b04".&lt;/p&gt;
&lt;p&gt;In the end, when the PARQUET files are created, the metadata from the table I just presented is collected, along with information extracted from parsing the contents of the XML file. Each of the metadata is then represented at the text line level. If you compare &lt;a href="https://huggingface.co/datasets/CATMuS/modern"&gt;McCATMuS&lt;/a&gt; with &lt;a href="https://huggingface.co/datasets/CATMuS/medieval"&gt;CATMuS Medieval&lt;/a&gt; using HuggingFace's dataset viewer, you can see that they don't use exactly the same metadata.&lt;/p&gt;
&lt;p&gt;"Language", "region type" and "line type" (which are based on the segmOnto classification), "project" and "gen_split" are common to both datasets, along with "shelfmark" I just described above. They both have a "genre" column with similar values (treatise, epistolary, document of practice, etc.). In the case of CATMuS Medieval, "genre" is complemented by "verse" (prose, verse).&lt;/p&gt;
&lt;p&gt;Following Thibault's advice, I defined the creation date of a text line using two numbers ("not_before" and "not_after") instead of a single "century" value. This allows for a precise dating when it is possible or on the contrary, to spread the dating over several centuries when it cannot be avoided, which is more accurate in both cases.&lt;/p&gt;
&lt;p&gt;McCATMuS mixes printed, handwritten and typewritten documents, so it was important to have a "writing type" column to help filter the dataset based on this information, in cases where one does not want to mix them. This metadata also makes it possible to use McCATMuS to train a classifier capable of distinguishing between the different types of writing. CATMuS Medieval on the other hand presents only handwritten sources, so such a metadata would be useless and is able to rely on paleographic classifications to characterize each text line based on a "script type" metadata, that includes values such as "caroline", "textualis", "hybrida", etc.&lt;/p&gt;
&lt;p&gt;McCATMuS also has a "color" column that helps sort text lines based on whether the source image is colored (true) or in grayscale (false).&lt;/p&gt;
&lt;p&gt;Although I reused the scripts developed by Thibault to build this dataset, I had to make several modifications to include this new metadata in the PARQUET files and to add additional filtering to the text lines. This included updating the mapping to the segmOnto vocabulary to match what existed in my datasets, or filtering some types of lines such as those identified as signatures.&lt;sup id="fnref:signatures"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/021/#fn:signatures"&gt;2&lt;/a&gt;&lt;/sup&gt; I also included an update of "writing_type" at the line level whenever the value in "line_type" allowed it to be controlled. &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;":handwritten"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;line_type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;writing_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"handwritten"&lt;/span&gt;
    &lt;span class="n"&gt;line_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_type&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;":handwritten"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="s2"&gt;":print"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;line_type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;writing_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"printed"&lt;/span&gt;
    &lt;span class="n"&gt;line_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_type&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;":print"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="s2"&gt;":typewritten"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;line_type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;writing_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"typewritten"&lt;/span&gt;
    &lt;span class="n"&gt;line_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_type&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;":typewritten"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;writing_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metadata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"writing_type"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the end, having built such a dataset (the first version of McCATMuS contains 117 text lines!) with such a variety of metadata is very satisfying although there is room for improvement. I have already mentioned that it would be interesting to have a greater variety of languages in McCATMuS. I also know that some of the values in "writing_type" are not completely accurate so adding a control based on a classifier might be interesting. Finally, I've noticed that some transcriptions in the "FoNDUE_Wolfflin_Fotosammlung" dataset are not correct at all, probably due to an automatic transcription that wasn't corrected.&lt;/p&gt;
&lt;p&gt;However, before we dive into improving McCATMuS, it's important to first examine the accuracy of the models that can be built on top of it! This will be the topic of the next and last post in this series!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:chocomufin"&gt;
&lt;p&gt;To learn more about how &lt;a href="https://github.com/PonteIneptique/choco-mufin?tab=readme-ov-file#commands"&gt;&lt;code&gt;chocomufin convert&lt;/code&gt;&lt;/a&gt; works, just read the software's short documentation. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/021/#fnref:chocomufin" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:signatures"&gt;
&lt;p&gt;I don't think it makes sense to include signatures in a dataset to train a generic model, since the transcription of such lines can be very context specific. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/021/#fnref:signatures" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>CATMuS</category><category>datasets</category><category>HTR</category><guid>https://alix-tz.github.io/phd/posts/021/</guid><pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate></item><item><title>020 - McCATMuS #3 - Datasets selection</title><link>https://alix-tz.github.io/phd/posts/020/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;HTR-United made identifying candidate datasets for McCATMuS a piece of cake. Once the rest of the CATMuS community agreed with the period to be covered by a "modern and contemporary" dataset, I created a simple script to parse the content of the HTR-United catalog and make a list of existing datasets covering documents written in Latin alphabet and matching our time criteria. &lt;/p&gt;
&lt;p&gt;Actually, here is the script!&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;url_latest_htrunited&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"https://raw.githubusercontent.com/HTR-United/htr-united/master/htr-united.yml"&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;yaml&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;pandas&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="c1"&gt;# get latest htr-united.yml from main repository&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url_latest_htrunited&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;catalog&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;safe_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;in_time_scope&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;century_scope_min&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1600&lt;/span&gt;
    &lt;span class="n"&gt;century_scope_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2100&lt;/span&gt;
    &lt;span class="c1"&gt;# this means that we allow datasets that intersect with the period&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"notBefore"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;century_scope_min&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"notAfter"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;century_scope_min&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"notBefore"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;century_scope_max&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"notAfter"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;century_scope_max&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;

&lt;span class="n"&gt;filtered_by_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;catalog&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;in_time_scope&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"time"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{})):&lt;/span&gt;
        &lt;span class="n"&gt;filtered_by_date&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Found &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filtered_by_date&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; entries matching the time scope."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;targeted_script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Latn"&lt;/span&gt;
&lt;span class="n"&gt;filtered_by_script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;filtered_by_date&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;targeted_script&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"iso"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"script"&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt;
        &lt;span class="n"&gt;filtered_by_script&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Found &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filtered_by_script&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; entries matching the script criteria."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;cols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Script Type"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Time Span"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Languages"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Repository"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Project Name"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Dataset Name"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;metadata_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;selected_entries&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;filtered_by_script&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;selected_entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;""&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;languages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"language"&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;languages&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Languages"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;languages&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;languages&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Languages"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;", "&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;languages&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Couldn't find a field for language in this repository"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Languages"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"no language"&lt;/span&gt;
    &lt;span class="c1"&gt;# get centuries/y&lt;/span&gt;
    &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Time Span"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"time"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"notBefore"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;-&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"time"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"notAfter"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;
    &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Project Name"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"project-name"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"no project name"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;repository&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"url"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"no url found"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"https://github.com/"&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Repository"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"https://github.com/"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"https://zenodo.org/"&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Repository"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"https://zenodo.org/"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"zenodo:"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Repository"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;repository&lt;/span&gt;
    &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Dataset Name"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"title"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"no title found"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;script_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"script-type"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;script_type&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"only-typed"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Script Type"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Print"&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;script_type&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"only-manuscript"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Script Type"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Handwritten"&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Script Type"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Mixed"&lt;/span&gt;
    &lt;span class="n"&gt;metadata_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;metadata_df&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;

&lt;span class="n"&gt;metadata_df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I saved the output as a CSV and proceeded to go through each of the selected datasets and its metadata. I checked several things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I made sure the datasets were available and easy to download. For example, I excluded those requiring manual image retrieval.&lt;/li&gt;
&lt;li&gt;I checked the format of the data because I decided to initially focus only on datasets available in ALTO XML and PAGE XML.&lt;/li&gt;
&lt;li&gt;I controlled the overall compatibility between the transcription guidelines used for the dataset and those designed by CATMuS.&lt;/li&gt;
&lt;li&gt;I also checked the conformity of the dataset when trying to import it into eScriptorium. This import allowed me to detect when there was a discrepancies between the names of the image files and the value for the source image in the XML file which prevented the import from successfully running.&lt;sup id="fnref:images"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/020/#fn:images"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Loading a sample of the dataset in eScriptorium also allowed me to visually control other incompatibilities with CATMuS that may not have been documented by the producers of the data.&lt;sup id="fnref:segmentation"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/020/#fn:segmentation"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;/li&gt;
&lt;li&gt;Finally, I considered the structure of the repository and, when necessary, the facility to reorganize it into a single &lt;code&gt;data/&lt;/code&gt; folder containing the images and the XML files, often distributed among sub-folders.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I assigned each dataset a priority number from 1 to 6. The lowest number was for dataset compatible with CATMuS without any modification (no dataset was giving a priority rank of 1...) and 6 for massive datasets that would require a nerve-racking script to be built correctly. My grading system is shown below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1=ready as is&lt;/li&gt;
&lt;li&gt;2=need to be &lt;a href="https://github.com/PonteIneptique/choco-mufin"&gt;chocomufin&lt;/a&gt;-ed&lt;/li&gt;
&lt;li&gt;3=require manual corrections but the dataset is very small, or the dataset is chocomufin/catmus compatible but requires a script to build it&lt;/li&gt;
&lt;li&gt;4=require manual corrections but the dataset is relatively big, or require a script to be fixed&lt;/li&gt;
&lt;li&gt;5=require manual corrections but the dataset is really big&lt;/li&gt;
&lt;li&gt;6=require manual corrections but the dataset is really big and require a personalized script to be built&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, &lt;a href="https://htr-united.github.io/share.html?uri=507bb514d"&gt;"Notaires de Paris - Bronod"&lt;/a&gt; had to be modified to comply with CATMuS requirements. This included replacing &lt;code&gt;[[&lt;/code&gt; and &lt;code&gt;]]&lt;/code&gt; &lt;a href="https://catmus-guidelines.github.io/html/guidelines/en/corrections_and_others.html"&gt;with &lt;code&gt;⟦&lt;/code&gt; and &lt;code&gt;⟧&lt;/code&gt;&lt;/a&gt;, or also to ignore lines containing &lt;code&gt;¥&lt;/code&gt;, a symbol used in LECTAUREP's datasets to transcribe signatures and paraphs. These were straightforward modifications, thanks to Chocomufin. On the complete opposite, &lt;a href="https://htr-united.github.io/share.html?uri=7a99090c5"&gt;"University of Denver Collections as Data - HTR Train and Validation Set JCRS_2020_5_27"&lt;/a&gt; is a massive dataset (2660 XML files), but there are segmentation errors in this dataset, creating erroneous transcriptions given the way the line is drawn, and the annotation of the superscripted text is not compatible with CATMuS. To make it compatible with CATMuS, it would be necessary to control and correct each page one by one.&lt;/p&gt;
&lt;p&gt;I chose to focus on datasets with priority 2 for the &lt;em&gt;first&lt;/em&gt; version of McCATMuS. Indeed, it'll be possible to add more datasets into CATMuS in later versions, so there was no need to spend too much time on manually cleaning datasets. I had 23 with priority 2 to go through.&lt;/p&gt;
&lt;p&gt;Identifying eligible datasets was not as time consuming as cleaning them and collecting additional metadata turned out to be. However, it gave me a good idea of the challenges I would face when trying to aggregate the datasets. I would have liked to be able to find a greater diversity of languages, but this is wasn't possible at this stage, mainly because many non-French datasets require more elaborate corrections than applying Chocomufin and were thus given a priority score higher than 2. &lt;/p&gt;
&lt;p&gt;The next post will be covering the tedious phase of data cleaning and aggregation, along with metadata collection!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:images"&gt;
&lt;p&gt;It was the case in "&lt;a href="https://htr-united.github.io/share.html?uri=c326a6fee"&gt;Données vérité de terrain HTR+ Annuaire des propriétaires et des propriétés de Paris et du département de la Seine (1898-1923)&lt;/a&gt; where the ALTO XML files are not explicitly linked to their corresponding source images. I believe it can be fixed, but it would require creating a script just for this purpose and the dataset presented other incompatibilities with CATMuS' guidelines. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/020/#fnref:images" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:segmentation"&gt;
&lt;p&gt;For example, "&lt;a href="https://htr-united.github.io/share.html?uri=43d1c93c7"&gt;Argus des Brevets&lt;/a&gt;" contains some segmentation errors that will need to be corrected manually. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/020/#fnref:segmentation" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>CATMuS</category><category>datasets</category><category>HTR</category><guid>https://alix-tz.github.io/phd/posts/020/</guid><pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate></item><item><title>019 - McCATMuS #2 - Defining guidelines</title><link>https://alix-tz.github.io/phd/posts/019/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;&lt;a href="https://x.com/JMFradeRue/status/1730191566508060883"&gt;Previous experiments&lt;/a&gt; have shown that conflicting transcription guidelines in training datasets make it less likely that a model will learn to transcribe correctly. This is particularly relevant when it comes to abbreviations and it's something to keep in mind when merging existing datasets. We didn't really address this when we trained the &lt;a href="https://inria.hal.science/hal-04094241"&gt;Manu McFrench model&lt;/a&gt; because it's difficult to retroactively align datasets to follow the same transcription rules. Unless you can afford to manually check every line, of course. In the case of Manu McFrench however, we only merged datasets that didn't solve abbreviations, so we ensured a minimum of cohesion.&lt;/p&gt;
&lt;p&gt;CATMuS was built on the foundation laid by CREMMALab and the &lt;a href="https://hal.science/hal-03716526"&gt;annotation guidelines&lt;/a&gt; developed by Ariane Pinche at the end of a seminar organized in 2021. These guidelines are intended to be generic, meaning they should be compatible with most transcription situations and are not project-specific. Following these guidelines will help data producers create ground truth that is compatible with data from other projects. It will also help those projects save time by not having to create transcription rules from scratch. From my experience, it is indeed easy for the members of a project discovering HTR to get caught up in the specifics of one project and forget what is and is not relevant (or even complicating) in the transcription phase.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;It's worth mentioning that a project can choose to follow some of the CATMuS guidelines, while maintaining more specific rules for certain cases. If that's the case, the CATMuS guidelines can (should?) be used as a reference point. Ideally, the specific rules defined by a project should be retro-compatible with CATMuS. For example, if a project decides to use a special character to mark the end of each paragraph, then in order to create a CATMuS-compatible version of the dataset, I should only have to replace or remove that character. In such cases, the special character that was chosen should be unambiguous and the rule should be explicitly presented.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As CREMMALab focused on the transcription of medieval manuscripts, so did the first CATMuS dataset and guidelines. As I said in my &lt;a href="https://alix-tz.github.io/phd/posts/018/"&gt;previous post&lt;/a&gt;, I focused on data covering the modern and contemporary periods, for which there was no equivalent to the CREMMALab guidelines. So, when extending CATMuS to these periods, I started with collecting existing guidelines and comparing them. I used the &lt;a href="https://hal.science/hal-03697382"&gt;CREMMA Medieval guidelines&lt;/a&gt;, the &lt;a href="https://gist.github.com/alix-tz/6f89444521bf1cab0522da520f7e4ff4"&gt;CREMMA guidelines for modern and contemporary documents&lt;/a&gt;, &lt;a href="https://hal.science/hal-04281804"&gt;SETAF's guidelines&lt;/a&gt; and &lt;a href="https://hal.science/hal-04557457"&gt;CATMuS Print's guidelines&lt;/a&gt; as a basis to elaborate the transcription rules for McCATMuS.&lt;/p&gt;
&lt;p&gt;For each rubric, I &lt;a href="https://docs.google.com/spreadsheets/d/1bFE-rRk6ZwgIHqXAOgwPo1s1zwQ-UPTLPnzjaRmTMsk/edit?usp=sharing"&gt;compared&lt;/a&gt; what each set of rules suggested, when they covered it. It was rare for all guidelines to align, but some cases were easy to solve. For example, all the guidelines recommended not to differentiate between regular s (&lt;code&gt;⟨s⟩&lt;/code&gt;) and long s (&lt;code&gt;⟨ſ⟩&lt;/code&gt;), except for the rules I had set for the modern and contemporary sources transcribed by CREMMA in 2021, before the CREMMALab seminar. It was thus decided that for McCATMuS there would be no distinction between all types of s's.&lt;/p&gt;
&lt;p&gt;Some rubrics needed to be discussed to figure out why the rule had been chosen in the first place by some of the projects, to decide which one to keep for McCATMuS. In February, I met with Ariane Pinche and Simon Gabay to go over the rubrics that still needed to be set. One example of a rule we discussed is how hyphenations are handled. CATMuS Medieval and the two CREMMA guidelines say to always use the same symbol (&lt;code&gt;⟨-⟩&lt;/code&gt;), whereas for the SETAF and CATMuS Print datasets, inline hyphenations (&lt;code&gt;⟨-⟩&lt;/code&gt;) are differentiated from hyphenations at the end of a line (&lt;code&gt;⟨¬⟩&lt;/code&gt;). Other symbols, like &lt;code&gt;⟨⸗⟩&lt;/code&gt;, were unanimously rejected.&lt;/p&gt;
&lt;p&gt;Two factors were considered when making those decisions: the feasibility of a retro-conversion for the existing datasets and the compatibility of the rule with a maximum of projects. In the case of hyphenations, I eventually decided to follow the same rule as CATMuS Medieval and CREMMA. On top of simplifying the compatibility of McCATMuS with CATMuS Medieval, I found that replacing all &lt;code&gt;⟨¬⟩&lt;/code&gt; with &lt;code&gt;⟨-⟩&lt;/code&gt;, rather than retroactively place &lt;code&gt;⟨¬⟩&lt;/code&gt; where there was indeed an hyphenation at the end of a line&lt;sup id="fnref:hyphen"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/019/#fn:hyphen"&gt;1&lt;/a&gt;&lt;/sup&gt; was much more straightforward.&lt;/p&gt;
&lt;p&gt;Once the set of rules was fixed, I used it to sort between the different datasets I had identified (I'll discuss this in the next post) and to decide which one would be retained for McCATMuS v1. I also defined the transformation scenarios necessary to turn each of these datasets into a CATMuS-compatible version. Then, once McCATMuS v1 was ready, I integrated the modern and contemporary guidelines into the &lt;a href="https://catmus-guidelines.github.io/"&gt;CATMuS website&lt;/a&gt;, where the transcription guidelines for CATMuS medieval were already published.&lt;/p&gt;
&lt;p&gt;Now that I am done integrating the rules set for McCATMuS into the website, I am confident that we have successfully designed rules that are overall compatible across the medieval, modern and contemporary periods, despite some unavoidable exceptions. Two good examples of the impossibility to cover a whole millennium of document production with the same rule are the &lt;a href="https://catmus-guidelines.github.io/html/guidelines/en/abbreviations.html"&gt;abbreviations&lt;/a&gt; and the &lt;a href="https://catmus-guidelines.github.io/html/guidelines/en/punctuation.html"&gt;punctuation signs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I've now explained how the transcription guidelines were established for McCATMuS. Next, I'll cover how they were integrated into existing datasets to create the first version of the McCATMuS dataset.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:hyphen"&gt;
&lt;p&gt;You can't assume that every instance of &lt;code&gt;⟨-⟩&lt;/code&gt; at the end of a line must be replaced with a &lt;code&gt;⟨¬⟩&lt;/code&gt;. In many cases, this can be a simple typographic decoration marking the end of a paragraph or the end of a title. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/019/#fnref:hyphen" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>CATMuS</category><category>guidelines</category><category>HTR</category><guid>https://alix-tz.github.io/phd/posts/019/</guid><pubDate>Tue, 20 Aug 2024 04:00:00 GMT</pubDate></item><item><title>018 - McCATMuS #1 - Overview</title><link>https://alix-tz.github.io/phd/posts/018/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;Last week, I attended &lt;a href="https://dh2024.adho.org/"&gt;ADHO's annual conference&lt;/a&gt; in Washington DC. I presented a short paper, co-authored with Floriane Chiffoleau and Hugo Scheithauer, about the documentation we wrote for eScriptorium (I wrote &lt;a href="https://alix-tz.github.io/phd/posts/018/010"&gt;a post&lt;/a&gt; about it last year and you can also find our presentation &lt;a href="https://inria.hal.science/hal-04594142"&gt;here&lt;/a&gt;). I was also a co-author on a long paper presented by Ariane Pinche on the &lt;a href="https://inria.hal.science/hal-04346939"&gt;CATMuS Medieval dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;CATMuS, which stands for "Consistent Approach to Transcribing ManuScripts", is a collective initiative and a framework to aggregate ground truth datasets using compatible &lt;a href="https://catmus-guidelines.github.io/"&gt;transcription guidelines&lt;/a&gt; for documents from different period written in romance languages. It started with &lt;a href="https://huggingface.co/datasets/CATMuS/medieval"&gt;CATMuS Medieval&lt;/a&gt;, but since January this year, I have been working on a version of CATMuS for the modern and contemporary period. &lt;/p&gt;
&lt;p&gt;While I should (and will) try to publish a data paper on CATMuS Modern &amp;amp; Contemporary (I'll call it McCatmus from now on), I figured I could start with a series of blog posts here. I want to describe the various steps I followed in order to eventually release &lt;a href="https://huggingface.co/datasets/CATMuS/modern"&gt;a dataset on HuggingFace&lt;/a&gt; and hopefully soon the corresponding transcription model.&lt;/p&gt;
&lt;p&gt;I started working on McCatmus in January, but because of a major personal event (I moved to Canada!), it took seven month of stop-and-go before the release of the V1. This was particularly challenging due to the scale of the project and its technicality (it was hard to get back into McCatmus after several weeks of interruption, which I had to do several times).&lt;/p&gt;
&lt;p&gt;To add to this complexity, McCatmus was also a multi-front operation. Indeed, to create McCatmus, it was necessary to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;define transcription guidelines in collaboration with other data producers,&lt;/li&gt;
&lt;li&gt;identify datasets compatible with the guidelines and set priorities,&lt;/li&gt;
&lt;li&gt;actually make all the dataset compatible with each other and clean some of the data,&lt;/li&gt;
&lt;li&gt;model and collect metadata that made sense for this dataset,&lt;/li&gt;
&lt;li&gt;release the dataset and fix the issues that came up.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To this date, two tasks remain on my to-do list for McCatmus: train a transcription model corresponding to this dataset and compare it with other existing ones, and make sure to have a publication describing this dataset and its usefulness.&lt;/p&gt;
&lt;p&gt;My plan is to dedicate one post to the creation of the guidelines for the dataset, then a post about the identification and collection of the datasets used in McCatmus v1, and then I'll wrap up with a post about the process to create the dataset, the metadata and the release. Stay tuned!&lt;/p&gt;</description><category>CATMuS</category><category>HTR</category><guid>https://alix-tz.github.io/phd/posts/018/</guid><pubDate>Wed, 14 Aug 2024 04:00:00 GMT</pubDate></item><item><title>016 - Text Recognition, Large Models and Expectations</title><link>https://alix-tz.github.io/phd/posts/016/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;Since the boom around ChatGPT almost a year ago, I've heard several people wondering if "tools like ChatGPT" were more efficient than HTR models trained with &lt;a href="https://kraken.re"&gt;Kraken&lt;/a&gt; and the like. The glimmer of hope in their eyes was most likely lit by their own struggle to set successful and/or efficient HTR campaigns with more traditional tools. The capacity of Large Language Models (LLMs) to reformulate a text&lt;sup id="fnref:spina"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/016/#fn:spina"&gt;1&lt;/a&gt;&lt;/sup&gt; or, more specifically, of Large Multimodal Models (LMMs) to generate text based on a visual input may indeed lead people to believe that HTR technologies built on &lt;a href="https://poloclub.github.io/cnn-explainer/"&gt;CNNs&lt;/a&gt; are on the verge of being flipped upside-down.&lt;sup id="fnref:multimodal_turn"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/016/#fn:multimodal_turn"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Annika Rockenberger recently conducted a series of small experiments on the matter and wrote &lt;a href="https://greflinger.hypotheses.org/739"&gt;an interesting blog post&lt;/a&gt; about it. Let's summarize it!&lt;/p&gt;
&lt;p&gt;She signed up for a premium subscription (25$/mo) to be able to chat with &lt;a href="https://openai.com/gpt-4"&gt;GPT4&lt;/a&gt;, which allows users to upload images. Then she submitted printed or handwritten documents she would normally transcribe with &lt;a href="https://readcoop.eu/transkribus"&gt;Transkribus&lt;/a&gt; and assessed the results. She found that GPT4 was fairly good on ancient print (German Fraktur) and that it was even able to follow transcription guidelines if provided with an example. However on a letter bearing handwritten cursive, the model completely hallucinated the content and attempted a transcription in the wrong language. This didn't change when she provided more context on the document. Rockenberger concludes that there is a potential for using ChatGPT for HTR but that the capacity of scaling it up is completely unsure and that learning how to provide good prompts to get the appropriate results is a challenge. I would also add that in the end, Rockenberger paid 25$ to get 10 lines of raw text, whereas with software like Transkribus or eScriptorium, she would also get a standard structured output.&lt;/p&gt;
&lt;p&gt;So, in other words, after reading Rockenberger's post, one can conclude that GPT4 (or, better, similar free and open source models) does have a potential for "quick and dirty-ish" OCR. However, I would argue that users tempted by this strategy might still miss an important point: even LMM-based tools will requires a little bit of organization and precision from the users. This, I find, often lacks in unsuccessful HTR campaigns. LMMs could generate a good output, but you will likely have to pay a counterpart one way or the other(s): with lower text recognition quality, with hallucinated text content, with impoverished non-structured output, with premium fees, etc.&lt;/p&gt;
&lt;p&gt;Earlier this year, an article proposed by &lt;a href="https://arxiv.org/abs/2305.07895"&gt;Liu et al. (2023)&lt;/a&gt;, "On the Hidden Mystery of OCR in Large Multimodal Models", explored almost exactly the same topic but in a more comprehensive way. Their article presents an extensive survey of how well several Large &lt;a href="https://en.wikipedia.org/wiki/Multimodal_learning"&gt;Multimodal&lt;/a&gt; Models (LMMs) performed on "zero-shot" tasks.&lt;/p&gt;
&lt;p&gt;Zero-shot refers to the act of requesting an output from an LLM or a LMM without training it for this task in particular. It is very similar to Rockenberger's first attempt with GPT4, when she uploaded the image of a printed document and asked for its transcription. In such a case, she relied on the capacity of the model to transfer its knowledge to the specific tasks of Text Recognition, on a specific type of documents (historical printed text).&lt;/p&gt;
&lt;p&gt;Other terms are often associated with "zero-shot:" "one-shot" and "few-shot". One-shot is equivalent to Rockenberger's second attempt: when she showed GPT4 an example of the output she expected on the 10 first lines of the documents, and requested that the model copied her strategy to generate the transcription of the 10 next lines. Few-shot would mean showing several pages and several expected output to the model before asking for the transcription of a new document.&lt;sup id="fnref:shot-definition"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/016/#fn:shot-definition"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The paper focused on currently available LMMs representing five different approaches for training LMMs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://huggingface.co/docs/transformers/model_doc/blip-2"&gt;BLIP-2&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2204.14198"&gt;Flamingo&lt;/a&gt;/&lt;a href="https://laion.ai/blog/open-flamingo/"&gt;Open-Flamingo&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://llava-vl.github.io/"&gt;LLaVa&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://minigpt-4.github.io/"&gt;miniGPT4&lt;/a&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;a href="https://huggingface.co/spaces/MAGAer13/mPLUG-Owl"&gt;mPLUG-Owl&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They evaluated the models on 4 tasks: text recognition, text-based visual question answering, key information extraction and handwritten mathematical expression recognition. Here are a few examples of what these tasks entail, as illustrated in the original article (on the images, P stands for Prediction and GT for Ground Truth):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;Task&lt;/th&gt;
&lt;th style="text-align: center;"&gt;Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Text Recognition&lt;/td&gt;
&lt;td style="text-align: center;"&gt;&lt;img alt="Examples of failed Text Recognition" src="https://alix-tz.github.io/phd/images/LLM_text_recogntion.png" title="Four images contained printed of handwritten words along with the ground truth (expected transcription) and the prediction generated by the models. For example, the model predicted 'chocolate' when the expected transcription was 'choco'"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Visual Question Answering&lt;/td&gt;
&lt;td style="text-align: center;"&gt;&lt;img alt="Examples of failed Visual Question Answering" src="https://alix-tz.github.io/phd/images/LLM_textVQA.png" title="Two images of real-life views along with a question used as a prompt, the expected answer and the predicted answer. For example, when asked 'What is the yellow number?' on the image of an airport luggage retrieval conveyor belt showing a clear '7' in yellow in the background, the model provided the following answer: 'The yellow number on the luggage trolley is 32"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;*Key Information Extraction&lt;/td&gt;
&lt;td style="text-align: center;"&gt;&lt;img alt="Examples of failed Key Information Extraction" src="https://alix-tz.github.io/phd/images/LLM_keyinfoextraction.png" title="Three images of real-life documents or textual information, along side with a question used as a prompt for the model, the expected answer and the predicted answer. For example, when asked 'what is the Sample No information in the input?', the model is expected to answer '1194-90' but answers 'The sample number is 33340'"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Handwritten Mathematical Expression Recognition&lt;/td&gt;
&lt;td style="text-align: center;"&gt;&lt;img alt="Examples of failed Handwritten Mathematical Expression Recognition" src="https://alix-tz.github.io/phd/images/LLM_HMExpr.png" title="Four example of failed attempts from the LMM to predict a LaTeX representation of handwritten mathematical expression: the numbers are wrong and/or the mathematical structure of the equations is made up"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- "Four images contained printed of handwritten words along with the ground truth (expected transcription) and the prediction generated by the models. For example, the model predicted 'chocolate' when the expected transcription was 'choco'.") | --&gt;
&lt;!--  "Two images of real-life views along with a question used as a prompt, the expected answer and the predicted answer. For example, when asked 'What is the yellow number?' on the image of an airport luggage retrieval conveyor belt showing a clear '7' in yellow in the background, the model provided the following answer: 'The yellow number on the luggage trolley is 32") | --&gt;
&lt;!--  "Three images of real-life documents or textual information, along side with a question used as a prompt for the model, the expected answer and the predicted answer. For example, when asked 'what is the Sample No information in the input?', the model is expected to answer '1194-90' but answers 'The sample number is 33340'") | --&gt;
&lt;!--  "Four example of failed attempts from the LMM to predict a LaTeX representation of handwritten mathematical expression: the numbers are wrong and/or the mathematical structure of the equations is made up") | --&gt;

&lt;p&gt;For each task, they used several datasets presenting different challenges. For each of these datasets and tasks, they retrieved the scores of the state-of-the-art (sota) for supervised methods and used them as a baseline. For example, for text recognition on the &lt;a href="https://fki.tic.heia-fr.ch/databases/iam-handwriting-database"&gt;IAM dataset&lt;/a&gt;, the sota method of AttentionHTR&lt;sup id="fnref:attentionhtr_ref"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/016/#fn:attentionhtr_ref"&gt;4&lt;/a&gt;&lt;/sup&gt; reaches a word accuracy of 91.24%.&lt;sup id="fnref:remark_wer"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/016/#fn:remark_wer"&gt;5&lt;/a&gt;&lt;/sup&gt; In comparison, Liu et al provide the following scores for the tested LMM on this dataset:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;test LMM&lt;/th&gt;
&lt;th style="text-align: center;"&gt;Score on IAM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;BLIP-2 OPT&lt;sub&gt;6.7b&lt;/sub&gt;&lt;/td&gt;
&lt;td style="text-align: center;"&gt;38.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;BLIP-2 FlanT5&lt;sub&gt;XXL&lt;/sub&gt;&lt;/td&gt;
&lt;td style="text-align: center;"&gt;40.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;OpenFlamingo&lt;/td&gt;
&lt;td style="text-align: center;"&gt;45.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;LLaVa&lt;/td&gt;
&lt;td style="text-align: center;"&gt;&lt;em&gt;50.40&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;MiniGPT4&lt;/td&gt;
&lt;td style="text-align: center;"&gt;28.90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;mPLUG-Owl&lt;/td&gt;
&lt;td style="text-align: center;"&gt;42.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;---------------&lt;/td&gt;
&lt;td style="text-align: center;"&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Supervised SOTA&lt;/td&gt;
&lt;td style="text-align: center;"&gt;&lt;strong&gt;91.24&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The illustrations provided by the article are all of failed attempts, but it corresponds to the overall impression conveyed by the results of the experiments. Indeed, compared to the state-of-the-art supervised methods, zero-shot tasks prompted to LMMs yield results largely outperformed, similar to what is visible in the case of text recognition on the IAM dataset. The only exception is BLIP-2 on a Text Recognition task on a dataset of artistic text (&lt;a href="https://github.com/xdxie/WordArt#wordart-dataset"&gt;WordArt&lt;/a&gt;) which is more challenging. The authors consider that this is a sign that LMMs have a promising potential for visually complex texts.&lt;/p&gt;
&lt;p&gt;A very important section of their paper is their remarks on the relationship between LMMs and semantics. Submitting non-word images to the LMMs, they find that the LMMs systematically over-correct the prediction and suggest real-words as an answer. Traditional text recognition approaches, on the other hand, are much less sensitive to the notion of likelihood for the words to recognize. Similarly, the need for semantics interferes with the LMMs' output, and they tend to more easily recognize common words and make up additional letters ("choco" is read as "chocolate"). Lastly, LMMs are insensitive to word length: they are unable to count how many letters are in the image of a word. These results are similar to what Rockenberger experienced with the handwritten letter: the model hallucinated words to compose a semantically plausible letter. But using the wrong date, the wrong names, and the wrong language.&lt;/p&gt;
&lt;p&gt;Liu et al conclude their paper reminding us that they experimented with the capacities of the models in the context of zero-shot prompts, whereas there are already successful attempts at fine-tuning LLMs and LMMs on specialized tasks, such as medical prediction. In fact, I think there already exist such attempts in the context of HTR as well: it seems to be the ambition of a model like Transkribus' Text Titan, released at the beginning of the Summer. It is based on a &lt;a href="https://youtu.be/zxQyTK8quyY?feature=shared"&gt;Transformer&lt;/a&gt; coupled with an LLM. Unfortunately, I wasn't able to find more information on this model, aside from the community-oriented communications released by Transkribus on their website (&lt;a href="https://readcoop.eu/introducing-transkribus-super-models-get-access-to-the-text-titan-i/"&gt;here&lt;/a&gt; and &lt;a href="https://help.transkribus.org/super-models"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:spina"&gt;
&lt;p&gt;In stead of a multimodal approach, Salvatore Spina explored the possibility to use a LLM-based tool like ChatGPT3 to post-process the result of HTR and correct the text. See: Spina, S. (2023). &lt;em&gt;Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT&lt;/em&gt; (arXiv:2308.02044). arXiv. &lt;a href="https://doi.org/10.48550/arXiv.2308.02044"&gt;arXiv.2308.02044&lt;/a&gt;. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/016/#fnref:spina" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:multimodal_turn"&gt;
&lt;p&gt;Multimodality is presented by some researchers of the Digital Humanities community as a real epistemological turn for the field. See for example: Smits, T., &amp;amp; Wevers, M. (2023). &lt;em&gt;A multimodal turn in Digital Humanities. Using contrastive machine learning models to explore, enrich, and analyze digital visual historical collections&lt;/em&gt;. Digital Scholarship in the Humanities, fqad008. &lt;a href="https://doi.org/10.1093/llc/fqad008"&gt;doi: 10.1093/llc/fqad008&lt;/a&gt; ; or Impett, L., &amp;amp; Offert, F. (2023). &lt;em&gt;There Is a Digital Art History&lt;/em&gt; (arXiv:2308.07464). arXiv. &lt;a href="https://doi.org/10.48550/arXiv.2308.07464"&gt;arXiv.2308.07464&lt;/a&gt;. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/016/#fnref:multimodal_turn" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:shot-definition"&gt;
&lt;p&gt;There are a few videos offering more or less detailed explanations on these expressions &lt;a href="https://www.youtube.com/watch?v=E6X1Ufhxtf0"&gt;in the context of prompting an LLM&lt;/a&gt;. However, this is not specific to LLM, it is often used in the context of &lt;a href="https://huggingface.co/tasks/zero-shot-classification"&gt;classification&lt;/a&gt; or &lt;a href="https://joeddav.github.io/blog/2020/05/29/ZSL.html"&gt;NLP&lt;/a&gt; tasks for example. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/016/#fnref:shot-definition" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:attentionhtr_ref"&gt;
&lt;p&gt;Kass, D., &amp;amp; Vats, E. (2022). &lt;em&gt;AttentionHTR: Handwritten Text Recognition Based on Attention Encoder-Decoder Networks&lt;/em&gt; (arXiv:2201.09390). arXiv. &lt;a href="https://doi.org/10.48550/arXiv.2201.09390"&gt;arXiv.2201.09390&lt;/a&gt;. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/016/#fnref:attentionhtr_ref" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:remark_wer"&gt;
&lt;p&gt;In this case, the WER is used as a baseline to compare different approaches. However, in general, it is not a good idea to only take into account Word accuracy to understand a model's performance in real life. This is something I discussed in &lt;a href="https://alix-tz.github.io/phd/posts/012/"&gt;this&lt;/a&gt; post. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/016/#fnref:remark_wer" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>Large Language Models</category><category>OCR</category><guid>https://alix-tz.github.io/phd/posts/016/</guid><pubDate>Tue, 28 Nov 2023 10:28:15 GMT</pubDate></item><item><title>015 - Block post and comprehensive Exam</title><link>https://alix-tz.github.io/phd/posts/015/</link><dc:creator>Alix Chagué</dc:creator><description>&lt;p&gt;When I created this blog last year, I wanted to post regularly on it. Something like once a month or once every other month. I didn't want to put pressure on myself for writing, but I also wanted to make sure that this blog would be alive. I often have ideas for topics for a post. But then, when comes the time to write, I blank out. It's not exactly that I don't know where to start, it's just that I sometimes can't figure out what is the message I want to convey. Like, if I have to summarize my blog post in 2 lines, what's the take-away? I get stuck when I cannot find an answer,but maybe I shouldn't worry that much about it. It's my blog after all, and maybe the message will come by the time I'm done writing. &lt;/p&gt;
&lt;p&gt;So, without further ado, let's dive in: I was &lt;em&gt;super&lt;/em&gt; excited this Summer after passing my comprehensive exam. I really wanted to write a post about it. I had a really packed Spring and beginning of Summer between going back to Montreal, teaching a class there, attending a Summer school, going to the DH2023 conference in Austria where I presented a short paper, a long paper and organized a workshop (big up to Thibault who was by my sides through all these Austrian adventures). And all of it culminated with that comprehensive exam in the middle of August. I really wanted to share how that went.&lt;/p&gt;
&lt;p&gt;But then, vacations, working on new deadlines, more vacations, more deadlines... And now it's already November and I don't know anymore what it was that I wanted to share about that exam. Aside from the fact that I passed it and that it's a pretty big milestone.&lt;/p&gt;
&lt;p&gt;The comprehensive examination, which is called "Examen de synthèse" in French, is not something common in France. In France, we now have a sort of yearly evaluation called the "Comité de Suivi Individuel" (or CSI), which is not a scholar evaluation but more of a check-up with your supervisors and a committee&lt;sup id="fnref:CSI"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/015/#fn:CSI"&gt;1&lt;/a&gt;&lt;/sup&gt; in charge of making sure that everything is alright. The reason I bring it alongside the Examen de Synthèse is because I also had my first CSI this Summer (at the very end of June). In France, you have to have a positive evaluation from the CSI in order to enroll in a new year of doctoral studies. Each year. But, actually the CSI and the Examen de Synthèse are not really that comparable.&lt;/p&gt;
&lt;p&gt;The Examen de Synthèse is a "real" examination and it happens only once during your doctoral curriculum. In my program at the University of Montréal, in 2023, it consisted in several phases.&lt;/p&gt;
&lt;p&gt;First of all, there is a phase dedicated to the composition of the jury. I had the pleasure to be examined not only by my three supervisors (Laurent Romary, Emmanuel Chateau-Dutier and Michael Sinatra), but also by &lt;a href="https://vitalirosati.com/"&gt;Marcello Vitali Rosati&lt;/a&gt;, from the University of Montréal, who acted as president, and &lt;a href="https://www.uqar.ca/universite/a-propos-de-l-uqar/departements/departement-des-lettres-et-humanites/gohier-maxime"&gt;Maxime Gohier&lt;/a&gt; from the University of Quebec in Rimouski. I must signal that my only regret is not to have been able to have a better gender parity in my jury. This is something I really hope to fix for my defense, but I will probably have other occasions to discuss this topic in the future.&lt;/p&gt;
&lt;p&gt;So, once the jury is composed, and once a calendar has been agreed on (I think &lt;em&gt;that&lt;/em&gt; was actually the most stressful part for me because of all the other things I had this Summer), a count down begins. First, I had to turn in three documents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a 12-15 page-long essay on my research project;&lt;/li&gt;
&lt;li&gt;a 30-reference long bibliography on the field of the Digital Humanities; and&lt;/li&gt;
&lt;li&gt;a short presentation of a proposed "practical" analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then a week later, the jury sent a question.&lt;sup id="fnref:question"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/015/#fn:question"&gt;2&lt;/a&gt;&lt;/sup&gt; I was given 1 week (168h exactly) to think about this question and write a response in the form of a 10-15 page-long essay. The jury had between a week and two weeks to read the response before an oral examination took place (on Zoom).&lt;/p&gt;
&lt;p&gt;The oral examination has some similarities with a PhD defense. It started with a 20 minute long presentation that I gave where I summarized my research project (10 minutes) and presented a technical analysis (10 minutes). I chose to focus my technical presentation on an experiment I have been conducting and on which I hope to communicate more in the near future. Then, after my presentation, there were two rounds of questions about my research project, my experiment or about the answer I formulated in my essay.&lt;sup id="fnref:more"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/015/#fn:more"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I am very happy that such an examination exists in the North American program. It may seem like a lot of stress (and it is), but I found that it is also a very good milestone to progress a lot towards the formalization of a research project. The oral examination is a great opportunity to present a project to people who don't necessarily know what you have been up to before, and it's a really really great occasion to get feedback.&lt;/p&gt;
&lt;p&gt;For example, the question that is sent by the jury, in the case of my program, is thought as a way to get you to think about a topic or a question that is either not tackled enough by your research proposal, or it's an invitation to consider new angles. You're not expected to turn in the perfect answer, of course, with barely a week to write it. But it forces you to form an opinion, explore possible hypotheses and may turn later into a whole chapter for your thesis.&lt;/p&gt;
&lt;p&gt;The comprehensive exam is a pass/no pass type of examination. There is no grade and if you fail, you can take it a second time. Like I said before at the beginning of this post, I passed. Therefore, starting from Fall 2023, I am now able to enroll as a "en rédaction" student (writing status) which has several consequences. Some seem very symbolic: for example, in English, I can now call myself a PhD candidate instead of a PhD student. But others not so much: tuitions for this new status are &lt;a href="https://registraire.umontreal.ca/droits-de-scolarite/couts-des-etudes/#c14807"&gt;much lower&lt;/a&gt; than when enrolling as a full-time student, dropping from 1,440$CA/trimester to 512$CA/trimester, and I believe this officially gives me the right to teach at graduate level.&lt;/p&gt;
&lt;p&gt;The comprehensive exam also marks the end of the phase during which I had to take courses. Now, with this new status, I am invited to focus solely on the redaction of my thesis, which opens up a whole new chapter for my PhD curriculum.&lt;sup id="fnref:pun"&gt;&lt;a class="footnote-ref" href="https://alix-tz.github.io/phd/posts/015/#fn:pun"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:CSI"&gt;
&lt;p&gt;I want to take this occasion to also thank &lt;a href="https://ciham.cnrs.fr/annuaire/membres_statutaires/ariane-pinche/"&gt;Ariane Pinche&lt;/a&gt; and &lt;a href="https://pro.univ-lille.fr/joana-casenave"&gt;Joana Casenave&lt;/a&gt;, who were willing to be the members of my committee for the CSI, for their precious feedback! :) &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/015/#fnref:CSI" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:question"&gt;
&lt;p&gt;The question was the following: "&lt;em&gt;Dans votre projet de recherche apparaît une tension importante: celle entre la spécificité des besoins particuliers de chaque projet et la volonté -- et la nécessité -- de produire des approches généralisables, qui puissent être employées dans le cadre de plusieurs projets. En vous appuyant sur votre bibliographie, et en vous concentrant notamment sur le cas du HTR, pourriez-vous analyser cette tension en soulevant en particulier la question de la littératie demandée (notamment dans la gestion des données) pour pouvoir personnaliser des approches computationnelles aussi complexes que les technologies HTR?&lt;/em&gt;" &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/015/#fnref:question" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:more"&gt;
&lt;p&gt;I want publish on my blog the documents I created for the comprehensive exam, but I need to find the best way to do it. I'll post an announcement when it will be available. &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/015/#fnref:more" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:pun"&gt;
&lt;p&gt;Thank you Jennifer for this wonderful pun! ;) &lt;a class="footnote-backref" href="https://alix-tz.github.io/phd/posts/015/#fnref:pun" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>cotutelle</category><category>courses</category><guid>https://alix-tz.github.io/phd/posts/015/</guid><pubDate>Tue, 07 Nov 2023 13:15:06 GMT</pubDate></item></channel></rss>